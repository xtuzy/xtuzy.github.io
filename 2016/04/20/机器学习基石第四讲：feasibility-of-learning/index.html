<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="日拱一卒，功不唐捐"><title>机器学习基石第四讲：feasibility of learning | Marcovaldo</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习基石第四讲：feasibility of learning</h1><a id="logo" href="/.">Marcovaldo</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/LeetCode/"><i class="fa fa-list"> LeetCode</i></a><a href="/Booklist/"><i class="fa fa-book"> Booklist</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习基石第四讲：feasibility of learning</h1><div class="post-meta">Apr 20, 2016<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/04/20/机器学习基石第四讲：feasibility-of-learning/" href="/2016/04/20/机器学习基石第四讲：feasibility-of-learning/#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Learning-is-Impossible"><span class="toc-number">1.</span> <span class="toc-text">Learning is Impossible?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Probability-to-the-Rescue"><span class="toc-number">2.</span> <span class="toc-text">Probability to the Rescue</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Connection-to-Learning"><span class="toc-number">3.</span> <span class="toc-text">Connection to Learning</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Connection-to-Real-Learning"><span class="toc-number">4.</span> <span class="toc-text">Connection to Real Learning</span></a></li></ol></div></div><div class="post-content"><p>刚刚完成<em>机器学习基石</em>的第四节，这一节讨论机器学习的可行性，用到了Hoeffding’s inequality等概率的知识，需要仔细揣摩。笔记整理在下面。</p>
<h2 id="Learning-is-Impossible"><a href="#Learning-is-Impossible" class="headerlink" title="Learning is Impossible?"></a>Learning is Impossible?</h2><p>前面的课程中曾提到过说学习可能是不可行的，为此我们还通过推导来证明PLA算法是否会停下来。那我们再来考虑这个问题，看看学习是否可行。</p>
<p>我们先来用我们的’human learning’来解决一个二元分类问题，如下图示，图中给出了3个标记为-1的图案和标记为+1的图案，然后我们来猜一下下面的那个图案应该标记为什么。<br><a id="more"></a><br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__1.jpg" alt="4_1"></p>
<p>其实无论你猜+1还是-1，都可能是错的，因为有不同的分类标准。我们观察一下上面的6个图案，我们可以发现标记为+1的3个图案都是对称的，标记为-1的3个图案都是非对称的，基于这样的分类标准我们可以将下面的图案标记为+1；我们还可以发现标记为-1的3个图案的左上角均为黑色，标记为+1的3个图案的左上角均为白色，基于这样的分类标准我们可以将下面的图案标记为-1。这说明，当问题存在着两个不同的标准时，我们无法判定我们的g的正确性。</p>
<p>下面再来一个例子。问题的输入是三位的二进制数字，输出是圈圈和叉叉，下图给出了训练集（其中有五组数据），我们用PLA去跑出一个g，并看看这个g跟我们理想的目标f是不是很接近。这个问题的输入只有8组数据，我们已经有了5组数据的输入，对于另外3组的输出我们可以遍历给出，也就是说另外3组数据的输出应该是下图中的1个（八选一）。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__2.jpg" alt="4_2"></p>
<p>我们可以发现这个问题的目标f有着8种不同的可能。我们说，很容易找到一个g，并证明这个g和目标f在训练集上是一致的，但我们不太容易在未知的数据上去证明这个g和f也是一致的（在这个问题中，无论你猜g是8个f中哪一个，我们都可以拿另外的7个说你是错的）。机器学习的目的是从已有的数据集出发，能够正确的处理未知的数据。而在这个例子中，我们无法证明hypothesis是否和目标f一致，也就不知道hypothesis对未知数据的处理是否是正确的，就好像我们没有从数据集中学到什么有用的东西。我们称这样的一个问题叫no free lunch。</p>
<p>其实这一节要说的是，我们无法证明hypothesis对未知数据的处理（标记或分类）一定是正确的，欢聚话说不能证明$h(x) = f(x)$。最后是本节小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__3.jpg" alt="4_3"></p>
<h2 id="Probability-to-the-Rescue"><a href="#Probability-to-the-Rescue" class="headerlink" title="Probability to the Rescue"></a>Probability to the Rescue</h2><p>继续讨论学习是否可行的问题，我们考虑是否存在一个东西可以对未知的东西进行一个推论。说现在有一个容器，装有大量的弹珠，有橘色，有绿色，我们想弄清橘色弹珠的比例（数量太大，不能人工一颗一颗去数）。</p>
<p>这里引入Hoeffding’s inequality。我们假设容器中橘色弹珠的比例为$\mu$（那绿色弹珠的比例就是$1-\mu$），且$\mu$未知。我们随机的在容器中抽取一个样本，样本容量为N，可以知道其中橘色弹珠的比例为$\nu$（绿色弹珠比例就是$1-\nu$），$\nu$已知。Hoeffding's inequality说，当N够大时，$\nu$和$\mu$差距很大的几率是很小的，不等式如下：<br>$$P[\left| \nu-\mu\right|>\epsilon] \leq 2 exp(-2\epsilon^2N)$$<br>现在我们可以说$\nu=\mu$“大概差不多是对的”（probably approximatly correct, PAC）。观察Hoeffding’s inequality，可以看到不等式右侧跟$\epsilon$和N有关，跟$\mu$无关。这就证明了我们拿抽样得来的$\nu$来估计$\mu$，当样本容量N越大时，$\nu$越接近$\mu$。</p>
<p>这一小节的结论是，样本容量N够大的话，我们就可以用$\nu$来估计$\mu$，我们会将这一结论用在下面的推导中。最后是小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__4.jpg" alt="4_4"></p>
<h2 id="Connection-to-Learning"><a href="#Connection-to-Learning" class="headerlink" title="Connection to Learning"></a>Connection to Learning</h2><p>回到$h(x) \overset{?}{=} f(x)$的问题，我们用一个个的弹珠来代表一个个的数据点：对于一个数据点，当$h(x) \neq f(x)$时，该数据点对应弹珠被漆成橘色；当$h(x) = g(x)$时，该数据点对应弹珠被漆成绿色。现在整个输入空间就变成了一个装满橘色、绿色弹珠的容器，我们现在要做的就是估计其中橘色弹珠的比例（其实$\mu$就是h(x)在整个数域空间上犯错的几率）。根据上一小节引入的Hoeffding’s inequality，在监督式学习中，我们就可以把h(x)在训练数据集上的表现当做一个抽样样本，我们就可以拿h(x)在训练样本上的犯错的几率来估计其在整个输入空间上犯错的几率。加上这些新东西，第一讲中的机器学习的流程图就变成了下面的样子：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__5.jpg" alt="4_5"></p>
<p>这里引入了$E_{out}(h) = \underset{x~P}{\epsilon}[h(x) \neq f(x)]$表示h(x)在整个输入空间上犯错的几率，$E_{in}(h) = \frac{1}{N}\sum_{n=1}^{N}[h(x) \neq f(x)]$表示h(x)在训练数据集上犯错的几率，我们现在拿后者来估计前者，将二者套入Hoeffding’s inequality有：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__6.jpg" alt="4_6"></p>
<p>注意，前面的hypothesis是特定的，其在整个输入空间上的犯错率和在训练数据集上的犯错率相当，如果其在训练数据集上的性能好，那么就可以说其在整个输入空间上是好的。但是H中包含大量的hypothesis，我们的机器学习算法往往是从中选择一个在训练数据集上犯错最小（就是$E_{in}$最小）的当作最终选定的hypothesis，但这样的hypothesis一定有好的泛化性能，答案是否定的。就是说，我们的算法不能保证最后拿到的hypothesis一定是前面讨论的那个特定的hypothesis。（这个地方不好理解）</p>
<p>关于前面的那个特定的hypothesis的讨论，下面给了一个图：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__7.jpg" alt="4_7"></p>
<p><em>好吧，这个地方不是特别清楚，所以写得也不够透彻，欢迎指正。</em> 最后是小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__8.jpg" alt="4_8"></p>
<h2 id="Connection-to-Real-Learning"><a href="#Connection-to-Real-Learning" class="headerlink" title="Connection to Real Learning"></a>Connection to Real Learning</h2><p>假设现在有M个hypothesis，下图中的M个容器分别代表他们在输入空间上的表现，然后我们分别用$E_{in}(h_i)$来估计$E_{out}(h_i)$。现在有$h_M$的$E_{in}(h_m)=0$，那我们要不要选它来当我们最后的hypothesis呢？我们先来讨论一个抛硬币的问题，一个班级中有150个人，每个人抛5次，假设其中一个人5次全是正面，那我们能说这个硬币很特别吗（对应前面的问题，我们能说$h_M$是好的么）？其实算一下就知道，150个人里边至少有一个人5次全是正面的几率是$1 - (\frac{1}{32})^{150} > 99%$。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__9.jpg" alt="4_9"></p>
<p>这里的硬币就是前面的弹珠，也就是我们的取样数据集。那么对一个hypothesis来说，坏的data是这样的：hypothesis在它上面的$E_{in}$很小，而$E_{out}$很大。Hoeffding's inequality是说我们抽到这样的坏数据的几率很小。就好比下图中，所有的$D_i$加起来是整个输入空间，其中坏的$D_i$是很少的。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__10.png" alt="4_10"></p>
<p>现在我们有M个hypothesis，那我们选到坏的data的几率肯定是增大了，我们来算一下：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__11.jpg" alt="4_11"></p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__12.jpg" alt="4_12"></p>
<p>现在我们说，在M有限的前提下，原来的机器算法跑出来的g应该是一个好的hypothesis。现在的机器学习流程变成了下面的样子。<em>其中还有些不明白的点，欢迎上过这个课程的同学指正</em></p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__13.jpg" alt="4_13"></p>
<p>到这里，这一讲的结论是在hypothesis数量有限的前提下，我们的机器学习是可行的。但前面说了，hypothesis是无限多的，这又如何解释呢，请看后面的课程。</p>
<p>小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF4__14.jpg" alt="4_14"></p>
<p><em>总之，这一讲很难，以后想到什么会改正补充。</em></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://marcovaldong.github.io/2016/04/20/机器学习基石第四讲：feasibility-of-learning/" data-id="cjfguskvy0037cgurpafw8z5j" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/机器学习基石/">机器学习基石</a></div><div class="post-nav"><a href="/2016/04/22/机器学习基石第五讲：training-versus-testing/" class="pre">机器学习基石第五讲：training versus testing</a><a href="/2016/04/19/机器学习基石第三讲：types-of-learning/" class="next">机器学习基石第三讲：types of learning</a></div><div data-thread-key="2016/04/20/机器学习基石第四讲：feasibility-of-learning/" data-title="机器学习基石第四讲：feasibility of learning" data-url="http://marcovaldong.github.io/2016/04/20/机器学习基石第四讲：feasibility-of-learning/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  owner: 'marcovaldong',
  repo: 'marcovaldong.github.io',
  oauth: {
    client_id: '3f1a34510c57772de8f8',
    client_secret: '69b8be94d1b53df548e46b9be32356b79e974d3c',
  },
})
gitment.render('container')
</script><div data-thread-key="2016/04/20/机器学习基石第四讲：feasibility-of-learning/" data-title="机器学习基石第四讲：feasibility of learning" data-url="http://marcovaldong.github.io/2016/04/20/机器学习基石第四讲：feasibility-of-learning/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://marcovaldong.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/信息隐藏/">信息隐藏</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Neural-Network/">Neural Network</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Theano/" style="font-size: 15px;">Theano</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Kaggle/" style="font-size: 15px;">Kaggle</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/信息隐藏/" style="font-size: 15px;">信息隐藏</a> <a href="/tags/Steganography/" style="font-size: 15px;">Steganography</a> <a href="/tags/语义分割/" style="font-size: 15px;">语义分割</a> <a href="/tags/面经/" style="font-size: 15px;">面经</a> <a href="/tags/Neural-Network/" style="font-size: 15px;">Neural Network</a> <a href="/tags/机器学习基石/" style="font-size: 15px;">机器学习基石</a> <a href="/tags/steganalysis/" style="font-size: 15px;">steganalysis</a> <a href="/tags/Pose-Estimation/" style="font-size: 15px;">Pose Estimation</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/01/My-reading-list2/">My reading list</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/27/小米面经/">小米面经</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/10/关于sematic-segmentation的几篇论文（二）/">关于sematic segmentation的几篇论文（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/论文阅读：RealTime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/">论文阅读：RealTime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/关于semantic-segmentation的几篇论文/">关于semantic segmentation的几篇论文</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/06/于众目睽睽之下隐藏图像：深度隐写术/">于众目睽睽之下隐藏图像：深度隐写术</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/08/深度学习在信息隐藏中的应用（下）/">深度学习在信息隐藏中的应用（下）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/06/深度学习在信息隐藏中的应用（上）/">深度学习在信息隐藏中的应用（上）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/14/使用Tensorflow实现Titanic比赛/">使用Tensorflow实现Titanic比赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/19/Python爬虫小结之Selenium/">Python爬虫小结之Selenium</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://killersdeath.github.io" title="抄作业的小东" target="_blank">抄作业的小东</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Marcovaldo.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'marcovaldo'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2be92f134440f46356c71aa55035a144";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>