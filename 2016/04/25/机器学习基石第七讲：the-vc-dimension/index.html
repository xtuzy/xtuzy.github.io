<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="日拱一卒，功不唐捐"><title>机器学习基石第七讲：the vc dimension | Marcovaldo</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">机器学习基石第七讲：the vc dimension</h1><a id="logo" href="/.">Marcovaldo</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/LeetCode/"><i class="fa fa-list"> LeetCode</i></a><a href="/Booklist/"><i class="fa fa-book"> Booklist</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">机器学习基石第七讲：the vc dimension</h1><div class="post-meta">Apr 25, 2016<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/04/25/机器学习基石第七讲：the-vc-dimension/" href="/2016/04/25/机器学习基石第七讲：the-vc-dimension/#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Definition-of-VC-Dimension"><span class="toc-number">1.</span> <span class="toc-text">Definition of VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#VC-Dimension-of-Perceptrons"><span class="toc-number">2.</span> <span class="toc-text">VC Dimension of Perceptrons</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Physical-Intuition-of-VC-Dimension"><span class="toc-number">3.</span> <span class="toc-text">Physical Intuition of VC Dimension</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Interpreting-VC-Dimension"><span class="toc-number">4.</span> <span class="toc-text">Interpreting VC Dimension</span></a></li></ol></div></div><div class="post-content"><p><em>机器学习基石</em>第七讲主要介绍了VC dimension，笔记整理在下面。</p>
<h2 id="Definition-of-VC-Dimension"><a href="#Definition-of-VC-Dimension" class="headerlink" title="Definition of VC Dimension"></a>Definition of VC Dimension</h2><p>上一讲我们找到了B(N,k)的上限，拿它和$N^{k-1}$做一个比较，发现当N够大时，前者比后者小得多。<br><a id="more"></a><br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__1.jpg" alt="7_1"></p>
<p>上一讲我们提到了VC bound：在dataset上，H中任意一个hypothesis发生坏事情的概率不超过一个很小很小的定值。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__2.jpg" alt="7_2"></p>
<p>这时可以说机器学习算法选择的g，其$E<em>{in}$和$E</em>{out}$相差很大的几率很小。</p>
<p>下面开始介绍VC Dimension，其是最大的non-break point的那个点，所以有$d_{vc}='minimum' -1$。那么当$N \leq d_{vc}$时，存在某个数据集可能会被某个hypothesis给shatter掉，当然不是一定；当$N > d_{vc}$时，数据集一定不会被H中的任一个hypothesis给shatter。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__3.jpg" alt="7_3"></p>
<p>下面是四个例子的vc dimension。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__4.jpg" alt="7_4"></p>
<p>前面我们说当break point露出一线曙光的时候有好的hypothesis，现在则变成了是有好的vc dimension的时候。</p>
<p>本小节测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__5.png" alt="7_5"></p>
<h2 id="VC-Dimension-of-Perceptrons"><a href="#VC-Dimension-of-Perceptrons" class="headerlink" title="VC Dimension of Perceptrons"></a>VC Dimension of Perceptrons</h2><p>现在回到课程开始时介绍的2D PLA算法。一方面，假设训练数据集线性可分，PLA算法就可以收敛，经过T次（足够大）迭代后就能够得到一个g有$E_{in}=0$。另一方面，数据集服从某一未知的分布P，存在一未知的目标f，此时的$d_{vc}=3$，那么当N足够大时，就有$E_{out}(g) \approx E_{in}(g)$。将这两条线融合在一起，我们就有了$E_{out}(g) \approx 0$，从而说明了学习是可行。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__6.jpg" alt="7_6"></p>
<p>现在我们尝试解决多维度的问题。前面知道了1D perceptron的$d_{vc}=2$，2D perceptrons的$d_{vc}=3$，我们猜测d-D perceptrons的$d_{vc} \stackrel{?}{=} d+1$。要证明它只需要两步：第一步，证明$d_{vc} \geq d+1$；第二步，证明$d_{vc} \leq d+1$。</p>
<p>证明之前先来一个小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__7.png" alt="7_7"></p>
<p>先来证明$d_{vc} \geq d+1$，我们只需证明存在d+1组输入数据能被某一个hypothesis给shatter掉。首先我们找到d+1组输入数据，存在矩阵X中，矩阵的每一行是一组数据。另外，矩阵X是可逆的。shatter的意思是说，对于任意$y=(y_1,y_2,...,y^{d+1})^T$都能找到一个w使得$sign(Xw)=y$。<br>如何做到这一点呢，看下面：<br>$$(Xw=y) \Rightarrow sign(Xw) = y \Longleftrightarrow w=X^{-1}y$$<br>所以说这一组特殊的数据集可以被shatter，从而证明了$d_{vc} \geq d+1$</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__8.jpg" alt="7_8"></p>
<p>小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__9.png" alt="7_9"></p>
<p>现在来证明$d_{vc} \leq d+1$。举一个二维的例子，选择下图中的一组数据集，注意其中$x_4$可由$x_1$、$x_2$和$x_3$线性组合而来。前面我们说过下图中的那个问号不可能被标记为叉叉，同样$x_4$不可能被标记为叉叉，原因看下图的公式。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__10.jpg" alt="7_10"></p>
<p>数据点之间的这种线性依赖关系限制了dichotomy的产生，这是一种特殊情况，但我们要证明的是所有的情况都不能被shatter。现在我们用一组d维的一般例子来解释。下图中的矩阵X包含d+2组数据，这d+2组数据肯定是线性相关的，然后重复前一张图的计算公式，我们同样也可以证明不能被shatter。这样我们就完成了对一般情况的证明。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__11.jpg" alt="7_11"></p>
<p>最后是小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__12.jpg" alt="7_12"></p>
<h2 id="Physical-Intuition-of-VC-Dimension"><a href="#Physical-Intuition-of-VC-Dimension" class="headerlink" title="Physical Intuition of VC Dimension"></a>Physical Intuition of VC Dimension</h2><p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__13.png" alt="7_13"></p>
<p>VC dimension的物理意义就是我的hypothesis在做二元分类的时候大概有多少的自由度，也告诉我们这个hypothesis能最多产生多少dichotomy。不同的VC dimension对应的好坏处见下图：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__14.jpg" alt="7_14"></p>
<p>这时，选择合适的VC dimension就变得很重要，而不同的VC dimension对应着不同的模型，所以选择模型是一件很重要的事。</p>
<p>本小节测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__15.jpg" alt="7_15"></p>
<h2 id="Interpreting-VC-Dimension"><a href="#Interpreting-VC-Dimension" class="headerlink" title="Interpreting VC Dimension"></a>Interpreting VC Dimension</h2><p>前面我们用一个不等式表示坏事情发生的概率，通过对该不等式的处理，我们得到了一个不等式来表示好事情发生的概率。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__16.jpg" alt="7_16"></p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__17.png" alt="7_17"></p>
<p>这里我们用$\Omega(N,H,\delta)$来表示上图中不等式的右侧，它表示在一个很高的几率内，$E_{out}-E_{in}$的值会小于$\Omega(N,H,\delta)$（当然，如果差值为负更好，说明g在未知数据上的犯错率比在训练集上还低）。</p>
<p>观察下图中的图像，可以看到随着$d_{vc}$的不断增大，$E_{in}$不断降低，$E_{out}$先降低后增加，模型复杂度不断增大。最合适的$d_{vc}^{*}$往往是在中间的。未来会利用这个图来设计更好的机器学习算法。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__18.jpg" alt="7_18"></p>
<p>另外，VC bound还可以说明样本的复杂度。假设已经给定了$\epsilon$、$\delta$、$d_{vc}$，问我们需要多大的训练集才可以得到这样的精度，请看下图。总结起来，理论上可能需要$N \approx 10,000d_{vc}$才能有一个好的精度，而实际上当$N \approx 10d_{vc}$时就已经足够了。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__19.png" alt="7_19"></p>
<p>这也说明这个VC bound实际上是很宽松的，宽松的原因是在整个推理过程中多次放大标准（要求太严），具体看下面四点。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__20.jpg" alt="7_20"></p>
<p>到这里，VC bound背后的一些数学意义和哲学意义就算介绍完了，虽然在以后的课程中涉及不太多，但大大加深了我们对机器学习的理解。</p>
<p>本节小测试：</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLF7__21.jpg" alt="7_21"></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://marcovaldong.github.io/2016/04/25/机器学习基石第七讲：the-vc-dimension/" data-id="cjfgusksf002lcgurwkik45aa" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/机器学习基石/">机器学习基石</a></div><div class="post-nav"><a href="/2016/04/25/机器学习基石第八讲：noise-and-error/" class="pre">机器学习基石第八讲：noise and error</a><a href="/2016/04/24/机器学习基石第六讲：theory-of-generalization/" class="next">机器学习基石第六讲：theory of generalization</a></div><div data-thread-key="2016/04/25/机器学习基石第七讲：the-vc-dimension/" data-title="机器学习基石第七讲：the vc dimension" data-url="http://marcovaldong.github.io/2016/04/25/机器学习基石第七讲：the-vc-dimension/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  owner: 'marcovaldong',
  repo: 'marcovaldong.github.io',
  oauth: {
    client_id: '3f1a34510c57772de8f8',
    client_secret: '69b8be94d1b53df548e46b9be32356b79e974d3c',
  },
})
gitment.render('container')
</script><div data-thread-key="2016/04/25/机器学习基石第七讲：the-vc-dimension/" data-title="机器学习基石第七讲：the vc dimension" data-url="http://marcovaldong.github.io/2016/04/25/机器学习基石第七讲：the-vc-dimension/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://marcovaldong.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/信息隐藏/">信息隐藏</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Neural-Network/">Neural Network</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Theano/" style="font-size: 15px;">Theano</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Kaggle/" style="font-size: 15px;">Kaggle</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/信息隐藏/" style="font-size: 15px;">信息隐藏</a> <a href="/tags/Steganography/" style="font-size: 15px;">Steganography</a> <a href="/tags/语义分割/" style="font-size: 15px;">语义分割</a> <a href="/tags/面经/" style="font-size: 15px;">面经</a> <a href="/tags/Neural-Network/" style="font-size: 15px;">Neural Network</a> <a href="/tags/机器学习基石/" style="font-size: 15px;">机器学习基石</a> <a href="/tags/steganalysis/" style="font-size: 15px;">steganalysis</a> <a href="/tags/Pose-Estimation/" style="font-size: 15px;">Pose Estimation</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/01/My-reading-list2/">My reading list</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/27/小米面经/">小米面经</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/10/关于sematic-segmentation的几篇论文（二）/">关于sematic segmentation的几篇论文（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/论文阅读：RealTime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/">论文阅读：RealTime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/关于semantic-segmentation的几篇论文/">关于semantic segmentation的几篇论文</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/06/于众目睽睽之下隐藏图像：深度隐写术/">于众目睽睽之下隐藏图像：深度隐写术</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/08/深度学习在信息隐藏中的应用（下）/">深度学习在信息隐藏中的应用（下）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/06/深度学习在信息隐藏中的应用（上）/">深度学习在信息隐藏中的应用（上）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/14/使用Tensorflow实现Titanic比赛/">使用Tensorflow实现Titanic比赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/19/Python爬虫小结之Selenium/">Python爬虫小结之Selenium</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://killersdeath.github.io" title="抄作业的小东" target="_blank">抄作业的小东</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Marcovaldo.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'marcovaldo'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2be92f134440f46356c71aa55035a144";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>