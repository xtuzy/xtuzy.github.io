<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="日拱一卒，功不唐捐"><title>使用Theano实现kaggle手写识别 | Marcovaldo</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">使用Theano实现kaggle手写识别</h1><a id="logo" href="/.">Marcovaldo</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/LeetCode/"><i class="fa fa-list"> LeetCode</i></a><a href="/Booklist/"><i class="fa fa-book"> Booklist</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">使用Theano实现kaggle手写识别</h1><div class="post-meta">Jun 12, 2016<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2016/06/12/使用Theano实现kaggle手写识别/" href="/2016/06/12/使用Theano实现kaggle手写识别/#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#实验代码"><span class="toc-number">1.</span> <span class="toc-text">实验代码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结论"><span class="toc-number">2.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="post-content"><p>前面学习了机器学习的一些基础知识，这两天尝试着做了几个小实验，手写就是利用theano来实现kaggle上的入门问题——手写识别。</p>
<p>Theano是一个Python库，允许我们来定义、优化和评估涉及多维数组的数学表达式，因此其是实现深度学习框架的一个很重要的模块。<a href="http://deeplearning.net/tutorial/" target="_blank" rel="external">Deep Learning Tutorials</a>则介绍了如何使用theano来搭建我们需要的深度学习网络来解决我们的实际问题。这里跳过了theano的基本知识（有需要的同学可以阅读<a href="http://deeplearning.net/software/theano/tutorial/" target="_blank" rel="external">Theano basic tutorial</a>），直接通过改造<a href="http://deeplearning.net/tutorial/" target="_blank" rel="external">Deep Learning Tutorials</a>中的<a href="http://deeplearning.net/tutorial/logreg.html#logreg" target="_blank" rel="external">Logistic Regression</a>、<a href="http://deeplearning.net/tutorial/mlp.html#mlp" target="_blank" rel="external">Multilayer perceptron</a>和<a href="http://deeplearning.net/tutorial/lenet.html#lenet" target="_blank" rel="external">Deep Convolutional Network</a>实现了kaggle的入门问题——手写识别，虽然精度不高，希望能给后面的同学提供一点点帮助。<br><a id="more"></a><br>本篇博客首先介绍使用逻辑回归来解决手写识别问题。kaggle手写识别问题中的数据来源于MNIST，只不过，其将70000条数据分成了train和test两个数据集，train集中包含42000条数据，且包含每条数据的label；test集中包含28000条数据，不包含每条数据的label。因此我们是通过train中的42000条数据去训练模型，然后再用得到的模型去标记test集中的28000条数据。本文采用了类似十折交叉验证（10-fold cross validation）的方法：将train集中的数据分成了十份，最后一份作为模型训练过程中的测试集，每次训练时选取前九份中的一份作为验证集，其余八份作为训练集，这样我们就可以得到同一个模型的九组参数设置。在预测阶段，前面得到的九组参数设置同时参与预测，具体做法是，对于同一组测试数据，我们分别用九组参数设置去预测，得到九个预测值，我们将这九个预测值中出现次数最多的那个label作为改组测试数据的最终预测值。</p>
<h2 id="实验代码"><a href="#实验代码" class="headerlink" title="实验代码"></a>实验代码</h2><p>首先是训练数据的读取函数，该函数有两个参数，一个参数file表示训练数据集所在文件，另一个参数partion表示我们选择训练集中哪一部分来作为验证集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_train</span><span class="params">(file)</span>:</span></div><div class="line">    rawData = []</div><div class="line">    file = csv.reader(open(file))</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:</div><div class="line">        rawData.append(line)</div><div class="line">    rawData.pop(<span class="number">0</span>) <span class="comment"># the first line is title</span></div><div class="line">    data = numpy.array(rawData).astype(numpy.int32)</div><div class="line">    <span class="comment"># 数据已存到data变量中</span></div><div class="line"></div><div class="line">    <span class="comment"># 下面将整个数据集分成train/validation/test三部分</span></div><div class="line">    train_x = [];   train_y = []</div><div class="line">    valid_x = [];   valid_y = []</div><div class="line">    test_x = [];    test_y = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25200</span>):</div><div class="line">        train_x.append(data[i][<span class="number">1</span>:<span class="number">785</span>])</div><div class="line">        train_y.append(data[i][<span class="number">0</span>])</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">25200</span>, <span class="number">37800</span>):</div><div class="line">        valid_x.append(data[i][<span class="number">1</span>:<span class="number">785</span>])</div><div class="line">        valid_y.append(data[i][<span class="number">0</span>])</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">37800</span>, <span class="number">42000</span>):</div><div class="line">        test_x.append(data[i][<span class="number">1</span>:<span class="number">785</span>])</div><div class="line">        test_y.append(data[i][<span class="number">0</span>])</div><div class="line">    <span class="keyword">del</span> data</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shared_dataset</span><span class="params">(data_xy, borrow=True)</span>:</span></div><div class="line">        <span class="string">""" Function that loads the dataset into shared variables</span></div><div class="line"></div><div class="line">        The reason we store our dataset in shared variables is to allow</div><div class="line">        Theano to copy it into the GPU memory (when code is run on GPU).</div><div class="line">        Since copying data into the GPU is slow, copying a minibatch everytime</div><div class="line">        is needed (the default behaviour if the data is not in a shared</div><div class="line">        variable) would lead to a large decrease in performance.</div><div class="line">        """</div><div class="line">        data_x, data_y = data_xy</div><div class="line">        shared_x = theano.shared(numpy.asarray(data_x), borrow=borrow)</div><div class="line">        shared_y = theano.shared(numpy.asarray(data_y), borrow=borrow)</div><div class="line">        <span class="comment"># When storing data on the GPU it has to be stored as floats</span></div><div class="line">        <span class="comment"># therefore we will store the labels as ``floatX`` as well</span></div><div class="line">        <span class="comment"># (``shared_y`` does exactly that). But during our computations</span></div><div class="line">        <span class="comment"># we need them as ints (we use labels as index, and if they are</span></div><div class="line">        <span class="comment"># floats it doesn't make sense) therefore instead of returning</span></div><div class="line">        <span class="comment"># ``shared_y`` we will have to cast it to int. This little hack</span></div><div class="line">        <span class="comment"># lets ous get around this issue</span></div><div class="line">        <span class="keyword">return</span> shared_x, T.cast(shared_y, <span class="string">'int32'</span>)</div><div class="line"></div><div class="line">    train_x, train_y = shared_dataset((train_x, train_y))</div><div class="line">    valid_x, valid_y = shared_dataset((valid_x, valid_y))</div><div class="line">    test_x, test_y = shared_dataset((test_x, test_y))</div><div class="line">    rval = [(train_x, train_y), (valid_x, valid_y),</div><div class="line">            (test_x, test_y)]</div><div class="line">    <span class="keyword">return</span> rval</div></pre></td></tr></table></figure>
<p>然后是test集的读取函数，结构类似于上一个函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_test</span><span class="params">(file)</span>:</span></div><div class="line">    rawData = []</div><div class="line">    file = csv.reader(open(file))</div><div class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file:</div><div class="line">        rawData.append(line)</div><div class="line">    rawData.pop(<span class="number">0</span>)  <span class="comment"># the first line is title</span></div><div class="line">    data = numpy.array(rawData).astype(numpy.int32)</div><div class="line">    test_set_x = []</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</div><div class="line">        test_set_x.append(data[i])</div><div class="line">    <span class="keyword">del</span> data</div><div class="line">    shared_data = theano.shared(numpy.asarray(test_set_x), borrow=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> shared_data</div></pre></td></tr></table></figure>
<p>下面是逻辑回归类，这个类来自于<a href="http://deeplearning.net/tutorial/" target="_blank" rel="external">Deep Learning Tutorials</a>中的<a href="http://deeplearning.net/tutorial/logreg.html#logreg" target="_blank" rel="external">Logistic Regression</a>，未作改动。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogisticRegression</span><span class="params">(object)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Multi-class logistic regression class</div><div class="line">    The logistic regression is fully described by a weight matrix :math:'W'</div><div class="line">    and bias vector :math:'b'. Classification is done by projecting data</div><div class="line">    points onto a set of hyperplanes, the distance to which is used to</div><div class="line">    determine to a class membership probability.</div><div class="line">    """</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, input, n_in, n_out)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Initialize the parameters of the logistic regression</div><div class="line">        :type input: theano.tensor.TensorType</div><div class="line">        :param input: symbolic variable that describes the input of the</div><div class="line">                        architecture (one minibatch)</div><div class="line">        :type n_in: int</div><div class="line">        :param n_in: number of input units, the dimension of the space in</div><div class="line">                        which the datapoints lie</div><div class="line">        :type n_out: int</div><div class="line">        :param n_out: number of output units, the dimension of the space in</div><div class="line">                        which the labels lie</div><div class="line">        """</div><div class="line">        <span class="comment"># start-snippet-1</span></div><div class="line">        <span class="comment"># initialize with 0 the weights W as a matrix of shape (n_in, n_out)</span></div><div class="line">        self.W = theano.shared(value=numpy.zeros((n_in, n_out),</div><div class="line">                               dtype=theano.config.floatX), name=<span class="string">'W'</span>, borrow=<span class="keyword">True</span>)</div><div class="line">        <span class="comment"># initialize the biases b as a vector of n_out 0s</span></div><div class="line">        self.b = theano.shared(value=numpy.zeros((n_out,),</div><div class="line">                                dtype=theano.config.floatX), name=<span class="string">'b'</span>, borrow=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">        <span class="comment"># symbolic expression for computing the matrix of class-membership</span></div><div class="line">        <span class="comment"># probabilities</span></div><div class="line">        <span class="comment"># Where:</span></div><div class="line">        <span class="comment"># W is a matrix where column-k represent the separation hyperplane for</span></div><div class="line">        <span class="comment"># class-k</span></div><div class="line">        <span class="comment"># x is a matrix where row-j represents input training sample-j</span></div><div class="line">        <span class="comment"># b is a vector where element-k represent the free parameter of hyperplane-k</span></div><div class="line">        self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W) + self.b)</div><div class="line"></div><div class="line">        <span class="comment"># symbolic description of how to compute prediction as class whose</span></div><div class="line">        <span class="comment"># probability is matrix</span></div><div class="line">        self.y_pred = T.argmax(self.p_y_given_x, axis=<span class="number">1</span>)</div><div class="line">        <span class="comment"># end-snippet-1</span></div><div class="line"></div><div class="line">        <span class="comment"># parameters of the model</span></div><div class="line">        self.params = [self.W, self.b]</div><div class="line"></div><div class="line">        <span class="comment"># keep track of model input</span></div><div class="line">        self.input = input</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">negative_log_likelihood</span><span class="params">(self, y)</span>:</span></div><div class="line">        <span class="string">"""</span></div><div class="line">        Return the mean of the negative log-likelihood of the prediction of</div><div class="line">        this model under a given target distribution.</div><div class="line"></div><div class="line">        :type y: theano.tensor.TensorType</div><div class="line">        :param y: corresponds to a vector that gives for each example the</div><div class="line">                    correct label</div><div class="line">        Note: we use the mean instead of the sum so that the learning rate</div><div class="line">                is less dependent on the batch size</div><div class="line">        """</div><div class="line">        <span class="comment"># start-snippet-2</span></div><div class="line">        <span class="comment"># y.shape[0] is (symbolically) the number of rows in y, i.e.,</span></div><div class="line">        <span class="comment"># number of examples (call it n) in the minibatch</span></div><div class="line">        <span class="comment"># T.arange(y.shape[0]) is a symbolic vector which will contain</span></div><div class="line">        <span class="comment"># [0, 1, 2,..., n-1] T.log(self.p_y_given_x) is a matrix of</span></div><div class="line">        <span class="comment"># Log-Probabilities (call it LP) with one row per example and</span></div><div class="line">        <span class="comment"># one column per class LP[T.arange(y.shape[0]),y] is a vector</span></div><div class="line">        <span class="comment"># v containing [LP[0, y[0]], LP[1, y[1]], LP[2, y[2]], ...,</span></div><div class="line">        <span class="comment"># LP[n-1, y[n-1]]] and T.mean(LP[T.arange(y.shape[0]), y]) is</span></div><div class="line">        <span class="comment"># the mean (across minibatch examples) of the elements in v, i.e.,</span></div><div class="line">        <span class="comment"># the mean log-likelihood across the minibatch.</span></div><div class="line">        <span class="keyword">return</span> -T.mean(T.log(self.p_y_given_x)[T.arange(y.shape[<span class="number">0</span>]), y])</div><div class="line">        <span class="comment"># end-snippet-2</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">errors</span><span class="params">(self, y)</span>:</span></div><div class="line">        <span class="string">"""Return a float representing the number of errors in the minibatch</span></div><div class="line">         over the total number of examples of the minibatch; zero one</div><div class="line">         loss over the size of the minibatch</div><div class="line">        :type y: theano.tensor.TensorType</div><div class="line">        :param y: corresponds to a vector that gives for each example the correct label</div><div class="line">        """</div><div class="line"></div><div class="line">        <span class="comment"># check if y has same dimension of y_pred</span></div><div class="line">        <span class="keyword">if</span> y.ndim != self.y_pred.ndim:</div><div class="line">            <span class="keyword">raise</span> TypeError(</div><div class="line">                <span class="string">'y should have the same shape as self.y_pred'</span>,</div><div class="line">                (<span class="string">'y'</span>, y.type, <span class="string">'y_pred'</span>, self.y_pred.type)</div><div class="line">            )</div><div class="line">        <span class="comment"># check if y is of the correct datatype</span></div><div class="line">        <span class="keyword">if</span> y.dtype.startswith(<span class="string">'int'</span>):</div><div class="line">            <span class="comment"># the T.neq operator returns a vector of 0s and 1s, where a</span></div><div class="line">            <span class="comment"># represents a mistake in prediction</span></div><div class="line">            <span class="keyword">return</span> T.mean(T.neq(self.y_pred, y))</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">raise</span> NotImplementedError()</div></pre></td></tr></table></figure>
<p>然后是模型训练函数，由<a href="http://deeplearning.net/tutorial/" target="_blank" rel="external">Deep Learning Tutorials</a>中的<a href="http://deeplearning.net/tutorial/logreg.html#logreg" target="_blank" rel="external">Logistic Regression</a>中的模型训练函数改造而来，其中参数多了一个partion，用来指定train集中的哪一部分作为此次训练的验证集。</p>
<p>其中参数的选择我们会在实验结论部分给出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sgd_optimization_mnist</span><span class="params">(learning_rate=<span class="number">0.3</span>, n_epochs=<span class="number">1000</span>,</span></span></div><div class="line">                       data_path=<span class="string">r'E:\Lab\digitrecognizer\train.csv'</span>, save_path=<span class="string">r'E:\Lab\digitrecognizer\my_best_model.pkl'</span>, partion=<span class="number">8</span>, batch_size=<span class="number">800</span>):</div><div class="line">    <span class="comment"># load dataset</span></div><div class="line">    datasets = read_cross_train(data_path, partion)</div><div class="line">    train_set_x, train_set_y = datasets[<span class="number">0</span>]</div><div class="line">    valid_set_x, valid_set_y = datasets[<span class="number">1</span>]</div><div class="line">    test_set_x, test_set_y = datasets[<span class="number">2</span>]</div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment"># compute number of minibatches for training, validation and testing</span></div><div class="line">    n_train_batches = train_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>] // batch_size     <span class="comment"># 25200 // batch_size</span></div><div class="line">    n_valid_batches = valid_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>] // batch_size     <span class="comment"># 12600 // batch_size</span></div><div class="line">    n_test_batches = test_set_x.get_value(borrow=<span class="keyword">True</span>).shape[<span class="number">0</span>] // batch_size       <span class="comment"># 4200 // batch_size</span></div><div class="line">    <span class="comment">######################</span></div><div class="line">    <span class="comment"># BUILD ACTUAL MODEL #</span></div><div class="line">    <span class="comment">######################</span></div><div class="line">    print(<span class="string">'...building the model'</span>)</div><div class="line"></div><div class="line">    <span class="comment"># allocate symbolic variables for the data</span></div><div class="line">    index = T.lscalar()  <span class="comment"># index to a [mini]batch</span></div><div class="line"></div><div class="line">    <span class="comment"># generate symbolic variables for input (x and y represent a minibatch)</span></div><div class="line">    x = T.imatrix(<span class="string">'x'</span>)  <span class="comment"># data, presented as rasterized images</span></div><div class="line">    y = T.ivector(<span class="string">'y'</span>)  <span class="comment"># labels, presented as 1D vector of [int] labels</span></div><div class="line"></div><div class="line">    <span class="comment"># construct the logistic regression class</span></div><div class="line">    <span class="comment"># Each MNIST image has size 28*28</span></div><div class="line">    classifier = LogisticRegression(input=x, n_in=<span class="number">28</span>*<span class="number">28</span>, n_out=<span class="number">10</span>)</div><div class="line">    <span class="comment"># the cost we minimize during training is the negative log likelihood of</span></div><div class="line">    <span class="comment"># the model in symbolic format</span></div><div class="line">    cost = classifier.negative_log_likelihood(y)</div><div class="line"></div><div class="line">    <span class="comment"># compiling a Theano function that computes the mistakes that are made by</span></div><div class="line">    <span class="comment"># the model on a minibatch</span></div><div class="line">    test_model = theano.function(</div><div class="line">        inputs=[index],</div><div class="line">        outputs=classifier.errors(y),</div><div class="line">        givens=&#123;</div><div class="line">            x: test_set_x[index * batch_size: (index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: test_set_y[index * batch_size: (index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    validate_model = theano.function(</div><div class="line">        inputs=[index],</div><div class="line">        outputs=classifier.errors(y),</div><div class="line">        givens=&#123;</div><div class="line">            x: valid_set_x[index * batch_size: (index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: valid_set_y[index * batch_size: (index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="comment"># compute the gradient of cost with respect to theta = (W,b)</span></div><div class="line">    g_W = T.grad(cost=cost, wrt=classifier.W)</div><div class="line">    g_b = T.grad(cost=cost, wrt=classifier.b)</div><div class="line"></div><div class="line">    <span class="comment"># specify how to update the parameters of the model as a list of</span></div><div class="line">    <span class="comment"># (variable, update expression) pairs.</span></div><div class="line">    updates = [(classifier.W, classifier.W - learning_rate * g_W),</div><div class="line">               (classifier.b, classifier.b - learning_rate * g_b)]</div><div class="line"></div><div class="line">    <span class="comment"># compiling a Theano function `train_model` that returns the cost, but in</span></div><div class="line">    <span class="comment"># the same time updates the parameter of the model based on the rules</span></div><div class="line">    <span class="comment"># defined in `updates`</span></div><div class="line">    train_model = theano.function(</div><div class="line">        inputs=[index],</div><div class="line">        outputs=cost,</div><div class="line">        updates=updates,</div><div class="line">        givens=&#123;</div><div class="line">            x: train_set_x[index * batch_size: (index + <span class="number">1</span>) * batch_size],</div><div class="line">            y: train_set_y[index * batch_size: (index + <span class="number">1</span>) * batch_size]</div><div class="line">        &#125;</div><div class="line">    )</div><div class="line"></div><div class="line">    <span class="comment">###############</span></div><div class="line">    <span class="comment"># TRAIN MODEL #</span></div><div class="line">    <span class="comment">###############</span></div><div class="line">    print(<span class="string">'... training the model'</span>)</div><div class="line"></div><div class="line">    patience = <span class="number">5000</span>  <span class="comment"># look as this many examples regardless</span></div><div class="line">    patience_increase = <span class="number">2</span>  <span class="comment"># wait this much longer when a new best is</span></div><div class="line">    <span class="comment"># found</span></div><div class="line">    improvement_threshold = <span class="number">0.995</span>  <span class="comment"># a relative improvement of this much is</span></div><div class="line">    <span class="comment"># considered significant</span></div><div class="line">    validation_frequency = min(n_train_batches, patience // <span class="number">2</span>)</div><div class="line">    <span class="comment"># go through this many</span></div><div class="line">    <span class="comment"># minibatche before checking the network</span></div><div class="line">    <span class="comment"># on the validation set; in this case we</span></div><div class="line">    <span class="comment"># check every epoch</span></div><div class="line"></div><div class="line">    best_validation_loss = numpy.inf</div><div class="line">    best_test_loss = numpy.inf</div><div class="line">    test_score = <span class="number">0.</span></div><div class="line">    start_time = timeit.default_timer()</div><div class="line">    done_looping = <span class="keyword">False</span></div><div class="line">    epoch = <span class="number">0</span></div><div class="line">    <span class="keyword">while</span> (epoch &lt; n_epochs) <span class="keyword">and</span> (<span class="keyword">not</span> done_looping):</div><div class="line">        epoch += <span class="number">1</span></div><div class="line">        <span class="keyword">for</span> minibatch_index <span class="keyword">in</span> range(n_train_batches):</div><div class="line">            minibatch_avg_cost = train_model(minibatch_index)</div><div class="line">            <span class="comment"># iteration number</span></div><div class="line">            iter = (epoch - <span class="number">1</span>) * n_train_batches + minibatch_index</div><div class="line"></div><div class="line">            <span class="keyword">if</span> (iter + <span class="number">1</span>) % validation_frequency == <span class="number">0</span>:</div><div class="line">                <span class="comment"># compute zero-one loss on validation set</span></div><div class="line">                validation_losses = [validate_model(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(n_valid_batches)]</div><div class="line">                this_validation_loss = numpy.mean(validation_losses)</div><div class="line">                print(<span class="string">'epoch %i, minibatch %i/%i, validation error %f %%'</span> % (</div><div class="line">                epoch, minibatch_index + <span class="number">1</span>, n_train_batches, this_validation_loss * <span class="number">100.</span>))</div><div class="line"></div><div class="line">                <span class="comment"># if we got the best validation score until now</span></div><div class="line">                <span class="keyword">if</span> this_validation_loss &lt; best_validation_loss:</div><div class="line">                    <span class="comment"># improve patience if loss improvement is good enough</span></div><div class="line">                    <span class="keyword">if</span> this_validation_loss &lt; best_validation_loss * \</div><div class="line">                            improvement_threshold:</div><div class="line">                        patience = max(patience, iter * patience_increase)</div><div class="line"></div><div class="line">                    best_validation_loss = this_validation_loss</div><div class="line">                    <span class="comment"># test it on the test set</span></div><div class="line">                    test_losses = [test_model(i)</div><div class="line">                                   <span class="keyword">for</span> i <span class="keyword">in</span> range(n_test_batches)]</div><div class="line">                    test_score = numpy.mean(test_losses)</div><div class="line"></div><div class="line">                    print(</div><div class="line">                        (<span class="string">'     epoch %i, minibatch %i/%i, test error of best model %f %%'</span>)</div><div class="line">                        % (epoch, minibatch_index + <span class="number">1</span>, n_train_batches, test_score * <span class="number">100.</span>))</div><div class="line">                    <span class="comment"># save the best model</span></div><div class="line">                    <span class="keyword">with</span> open(save_path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">                        pickle.dump(classifier, f)</div><div class="line">            <span class="keyword">if</span> patience &lt; iter:</div><div class="line">                done_looping = <span class="keyword">True</span></div><div class="line">                <span class="keyword">break</span></div><div class="line">    end_time = timeit.default_timer()</div><div class="line"></div><div class="line">    print(</div><div class="line">        (<span class="string">'Optimization complete with best validation score of %f %%, with test performance %f %%'</span>)</div><div class="line">        % (best_validation_loss * <span class="number">100.</span>, test_score * <span class="number">100.</span>))</div><div class="line">    print(<span class="string">'The code run for %d epochs, with %f epochs/sec'</span> % (</div><div class="line">        epoch, <span class="number">1.</span> * epoch / (end_time - start_time)))</div><div class="line">    print((<span class="string">'The code for file '</span> +</div><div class="line">           os.path.split(__file__)[<span class="number">1</span>] +</div><div class="line">           <span class="string">' ran for %.1fs'</span> % ((end_time - start_time))), file=sys.stderr)</div></pre></td></tr></table></figure>
<p>最后是预测函数，该函数有两个参数，参数data_path表示测试集所在文件，参数has_label表示测试集中是否含有label，有label的话预测函数会计算出错误率，没有label的话函数会将测试结果保存在文件answer.csv中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict_cross</span><span class="params">(has_label=<span class="number">1</span>, data_path=<span class="string">r'E:\Lab\digitrecognizer\train.csv'</span>)</span>:</span></div><div class="line"></div><div class="line">    <span class="keyword">if</span> has_label == <span class="number">1</span>:</div><div class="line">        <span class="comment"># load test set</span></div><div class="line">        <span class="comment"># data_path = r'E:\Lab\digitrecognizer\train.csv'</span></div><div class="line">        test_set_x, test_set_y = read_train(data_path)</div><div class="line">        test_set_x = test_set_x.get_value()</div><div class="line">        test_set_y = test_set_y.get_value()</div><div class="line"></div><div class="line">        <span class="comment"># from different pkl document load different model</span></div><div class="line">        classifiers = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">            model_path = <span class="string">'E:\Lab\digitrecognizer\model'</span> + str(i) + <span class="string">'.pkl'</span></div><div class="line">            classifier = pickle.load(open(model_path))</div><div class="line">            classifiers.append(classifier)</div><div class="line"></div><div class="line">        <span class="comment"># compile 9 predictor functions with different params</span></div><div class="line">        models = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">            model = theano.function(inputs=[classifiers[i].input], outputs=classifiers[i].y_pred)</div><div class="line">            models.append(model)</div><div class="line"></div><div class="line">        <span class="comment"># 做预测</span></div><div class="line">        predicted_labels = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">            predicted = models[i](test_set_x[:<span class="number">42000</span>])</div><div class="line">            predicted_labels.append(predicted)</div><div class="line">        predicted_label = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">42000</span>):</div><div class="line">            dictionary = &#123;<span class="string">'0'</span>: <span class="number">0</span>, <span class="string">'1'</span>: <span class="number">0</span>, <span class="string">'2'</span>: <span class="number">0</span>, <span class="string">'3'</span>: <span class="number">0</span>, <span class="string">'4'</span>: <span class="number">0</span>, <span class="string">'5'</span>: <span class="number">0</span>, <span class="string">'6'</span>: <span class="number">0</span>, <span class="string">'7'</span>: <span class="number">0</span>, <span class="string">'8'</span>: <span class="number">0</span>, <span class="string">'9'</span>: <span class="number">0</span>&#125;</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">                dictionary[str(predicted_labels[j][i])] += <span class="number">1</span></div><div class="line"></div><div class="line">            <span class="comment"># 字典处理，找到被9个模型预测最多的那个label作为该组输入的输出</span></div><div class="line">            label_number = max(dictionary.values())</div><div class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> dictionary:</div><div class="line">                <span class="keyword">if</span> dictionary[key] == label_number:</div><div class="line">                    predicted_label.append(int(key))</div><div class="line">                    <span class="keyword">break</span></div><div class="line">        err = <span class="number">0.</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">42000</span>):</div><div class="line">            print(<span class="string">"The %d th example's predict is %d, and it's target value is %d."</span> % (i, predicted_label[i], test_set_y[i]))</div><div class="line">            <span class="keyword">if</span> predicted_label[i] != test_set_y[i]:</div><div class="line">                err += <span class="number">1</span></div><div class="line"></div><div class="line">        print(<span class="string">"The error rate of the combined model in 1000 examples is %f ."</span> % (err/<span class="number">420</span>))</div><div class="line">        errorate = [] <span class="comment"># [8.875, 8.800, 8.925, 8.975, 8.375, 8.300, 8.925, 9.225, 8.925]</span></div><div class="line">        <span class="comment"># 分别计算九个模型在整个训练集上的错误率</span></div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">            err = <span class="number">0.</span></div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">42000</span>):</div><div class="line">                <span class="keyword">if</span> predicted_labels[i][j] != test_set_y[j]:</div><div class="line">                    err += <span class="number">1</span></div><div class="line">            errorate.append(err/<span class="number">420</span>)</div><div class="line">        print(<span class="string">"The mean error rate of 9 different models is %f"</span> % numpy.mean(errorate))</div><div class="line">        print(errorate)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="comment"># load test set</span></div><div class="line">        test_set_x = read_test(data_path)</div><div class="line">        test_set_x = test_set_x.get_value()</div><div class="line">        <span class="comment"># from different pkl document load different model</span></div><div class="line">        classifiers = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">            model_path = <span class="string">'E:\Lab\digitrecognizer\model'</span> + str(i) + <span class="string">'.pkl'</span></div><div class="line">            classifier = pickle.load(open(model_path))</div><div class="line">            classifiers.append(classifier)</div><div class="line"></div><div class="line">        <span class="comment"># compile 9 predictor functions with different params</span></div><div class="line">        models = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">            model = theano.function(inputs=[classifiers[i].input], outputs=classifiers[i].y_pred)</div><div class="line">            models.append(model)</div><div class="line"></div><div class="line">        <span class="comment"># 做预测</span></div><div class="line">        predicted_labels = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">            predicted = models[i](test_set_x[:<span class="number">28000</span>])</div><div class="line">            predicted_labels.append(predicted)</div><div class="line">        predicted_label = []</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">28000</span>):</div><div class="line">            dictionary = &#123;<span class="string">'0'</span>: <span class="number">0</span>, <span class="string">'1'</span>: <span class="number">0</span>, <span class="string">'2'</span>: <span class="number">0</span>, <span class="string">'3'</span>: <span class="number">0</span>, <span class="string">'4'</span>: <span class="number">0</span>, <span class="string">'5'</span>: <span class="number">0</span>, <span class="string">'6'</span>: <span class="number">0</span>, <span class="string">'7'</span>: <span class="number">0</span>, <span class="string">'8'</span>: <span class="number">0</span>, <span class="string">'9'</span>: <span class="number">0</span>&#125;</div><div class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">                dictionary[str(predicted_labels[j][i])] += <span class="number">1</span></div><div class="line"></div><div class="line">            <span class="comment"># 字典处理，找到被9个模型预测最多的那个label作为该组输入的输出</span></div><div class="line">            label_number = max(dictionary.values())</div><div class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> dictionary:</div><div class="line">                <span class="keyword">if</span> dictionary[key] == label_number:</div><div class="line">                    predicted_label.append(int(key))</div><div class="line">                    <span class="keyword">break</span></div><div class="line">        print(predicted_label)</div><div class="line">        print(len(predicted_label))</div><div class="line">        saveResult(predicted_label, <span class="string">r'E:\Lab\digitrecognizer\answer.csv'</span>)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveResult</span><span class="params">(result, file)</span>:</span></div><div class="line">    <span class="keyword">with</span> open(file, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</div><div class="line">        <span class="comment"># file = open(f, 'wb')</span></div><div class="line">        ob = csv.writer(f)</div><div class="line">        ob.writerow([<span class="string">"ImageId"</span>, <span class="string">"Label"</span>])</div><div class="line">        ids = range(<span class="number">1</span>, len(result)+<span class="number">1</span>)</div><div class="line">        ob.writerows(zip(ids, result))</div><div class="line">        f.close()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(file1, file2)</span>:</span></div><div class="line"></div><div class="line">    <span class="comment"># load the saved model</span></div><div class="line">    classifier = pickle.load(open(file1))</div><div class="line">    <span class="comment"># compile a predictor function</span></div><div class="line">    predict_model = theano.function(inputs=[classifier.input], outputs=classifier.y_pred)</div><div class="line"></div><div class="line">    <span class="comment"># make prediction</span></div><div class="line">    data_path = <span class="string">r'E:\Lab\digitrecognizer\test.csv'</span></div><div class="line">    test_set_x= read_test(data_path)</div><div class="line">    test_set_x = test_set_x.get_value()</div><div class="line">    predicted_values = predict_model(test_set_x[:<span class="number">28000</span>])</div><div class="line">    <span class="comment"># 保存预测结果</span></div><div class="line">    saveResult(predicted_values, file2)</div></pre></td></tr></table></figure>
<p>最后是主函数，如下所示，当然我们可以根据自己的实际需要去做调整。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    start_time = timeit.default_timer()</div><div class="line">    </div><div class="line">    <span class="comment"># 训练出9个模型</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">        save_model_path = <span class="string">r'E:\Lab\digitrecognizer\my_model'</span> + str(i) + <span class="string">'.pkl'</span></div><div class="line">        sgd_optimization_mnist(learning_rate=<span class="number">0.13</span>, n_epochs=<span class="number">1000</span>,</div><div class="line">                              data_path=<span class="string">r'E:\Lab\digitrecognizer\train.csv'</span>,</div><div class="line">                              save_path=save_model_path, partion=i, batch_size=<span class="number">800</span>)</div><div class="line">    <span class="comment"># 在train集上检验模型</span></div><div class="line">    <span class="comment"># predict_cross(has_label=1, data_path=r'E:\Lab\digitrecognizer\train.csv')</span></div><div class="line">    <span class="comment"># 在test集上做预测，并将最终结果存到文件answer.csv中</span></div><div class="line">    <span class="comment"># predict_cross(has_label=0, data_path=r'E:\Lab\digitrecognizer\test.csv')</span></div><div class="line">    </div><div class="line">    <span class="comment"># 使用单独的模型在test集上做测试，并保存测试结果</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">9</span>):</div><div class="line">        model_path = <span class="string">r'E:\Lab\digitrecognizer\model'</span> + str(i) + <span class="string">'.pkl'</span></div><div class="line">        save_path = <span class="string">r'E:\Lab\digitrecognizer\answer'</span> + str(i) + <span class="string">'.csv'</span></div><div class="line">        predict(model_path, save_path)</div><div class="line">    </div><div class="line">    <span class="comment"># 然后分别在kaggle上提交十组结果，观察正确率如何</span></div><div class="line">    </div><div class="line">    end_time = timeit.default_timer()</div><div class="line">    print(<span class="string">"Time consumption is %f sec."</span> % (end_time-start_time))</div></pre></td></tr></table></figure>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在参数的选择上，我们做了多组测试（该测试是选择train.csv中的前3/5座训练集，最后1/10做测试集，中间3/10做验证集得到的），最终选定了上面的参数，下面给出了一组对照数据。测试的机器是12年的，CPU为i3-2350M，主频为2。30GHZ，内存为6G，无GPU（机器太渣，没办法）。在写这篇博客时，我又试验了一下bacth_size大于1000的几种情况，等后续试验数据得出后，如果有更小的错误率，我会更新数据。</p>
<table>
<thead>
<tr>
<th>batch_size</th>
<th>learning_rate</th>
<th>epoches</th>
<th>seconds</th>
<th>epoches/sec</th>
<th>valid_err</th>
<th>test_err</th>
</tr>
</thead>
<tbody>
<tr>
<td>300</td>
<td>0.13</td>
<td>126</td>
<td>2207</td>
<td>0.057</td>
<td>9.786</td>
<td>9.904</td>
</tr>
<tr>
<td>500</td>
<td>0.13</td>
<td>270</td>
<td>2736</td>
<td>0.097</td>
<td>10.064</td>
<td>9.700</td>
</tr>
<tr>
<td>800</td>
<td>0.13</td>
<td>162</td>
<td>1186</td>
<td>0.137</td>
<td>9.767</td>
<td>9.425</td>
</tr>
<tr>
<td>800</td>
<td>0.3</td>
<td>394</td>
<td>2922</td>
<td>0.135</td>
<td>9.98</td>
<td>9.875</td>
</tr>
<tr>
<td>800</td>
<td>0.03</td>
<td>202</td>
<td>1369</td>
<td>0.147</td>
<td>10.083</td>
<td>10.075</td>
</tr>
<tr>
<td>1000</td>
<td>0.13</td>
<td>201</td>
<td>1205</td>
<td>0.167</td>
<td>9.792</td>
<td>9.475</td>
</tr>
<tr>
<td>1400</td>
<td>0.13</td>
<td>408</td>
<td>2281</td>
<td>0.1789</td>
<td>9.6111</td>
<td>9.500</td>
</tr>
<tr>
<td>1600</td>
<td>0.13</td>
<td>334</td>
<td>1590</td>
<td>0.2101</td>
<td>9.089</td>
<td>8.4375</td>
</tr>
<tr>
<td>3200</td>
<td>0.13</td>
<td>714</td>
<td>1974</td>
<td>0.3622</td>
<td>9.083</td>
<td>8.5313</td>
</tr>
<tr>
<td>4200</td>
<td>0.13</td>
<td>834</td>
<td>2529</td>
<td>0.3297</td>
<td>9.2540</td>
<td>9.0714</td>
</tr>
</tbody>
</table>
<p>单单针对MNIST数据集和逻辑回归模型，我们从上面这张表可以得出一些结论：batch_size越大，计算速度越快，精度慢慢有所提高；learning rate大的话epoches就会变大，也就是在整个train集上计算的次数多。</p>
<p>通过实验，我们得到9个模型在train.csv上的单独错误率分别为[7.783333333333333, 7.804761904761905, 7.457142857142857, 7.554761904761905, 7.9<br>97619047619048, 7.642857142857143, 7.571428571428571, 7.742857142857143, 7.16428<br>5714285715]，而综合9个模型去做预测的话在train.csv上的错误率为7.097619，比单独的模型的平均错误率减小了0.538%，可以说十折交叉验证的确提高了模型的性能，但感觉不明显。</p>
<p>然后，我们又综合9个模型去预测test.csv中的数据，提交到kaggle上的正确率为0.91429，下面截图为证。而9个模型分别单独去预测test.csv中的数据，得到的正确率分别为[0.91057, 0.90543, 0.90986, 0.91371, 0.91214]（数据还没有全部拿到，kaggle一天只允许提交5次），可以看到十折交叉验证的方法提高了0.4%的准确率，可能是实验方法不恰当，没有想象的高。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/theano_logistic_model_cross.png" alt="jietu1"></p>
<p>另外一个感受就是，theano实在太慢了，逻辑回归求一个模型大概需要跑20分钟，后面的mlp至少需要跑80度分钟，而卷积网络时间就更长了。等整理完了mlp和卷积网络的实验数据，就入门libgpuarray，好像利用GPU来做运算，比CPU快很多。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://marcovaldong.github.io/2016/06/12/使用Theano实现kaggle手写识别/" data-id="cjfguskiz001ccgurm21wrbp3" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a><a href="/tags/Theano/">Theano</a></div><div class="post-nav"><a href="/2016/07/08/Ubuntu14-04-Theano-OpenCL-libgpuarray实现GPU运算/" class="pre">Ubuntu14.04+Theano+OpenCL+libgpuarray实现GPU运算</a><a href="/2016/05/30/机器学习中使用的神经网络第十讲/" class="next">机器学习中使用的神经网络第十讲</a></div><div data-thread-key="2016/06/12/使用Theano实现kaggle手写识别/" data-title="使用Theano实现kaggle手写识别" data-url="http://marcovaldong.github.io/2016/06/12/使用Theano实现kaggle手写识别/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  owner: 'marcovaldong',
  repo: 'marcovaldong.github.io',
  oauth: {
    client_id: '3f1a34510c57772de8f8',
    client_secret: '69b8be94d1b53df548e46b9be32356b79e974d3c',
  },
})
gitment.render('container')
</script><div data-thread-key="2016/06/12/使用Theano实现kaggle手写识别/" data-title="使用Theano实现kaggle手写识别" data-url="http://marcovaldong.github.io/2016/06/12/使用Theano实现kaggle手写识别/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://marcovaldong.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/信息隐藏/">信息隐藏</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Neural-Network/">Neural Network</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Theano/" style="font-size: 15px;">Theano</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Kaggle/" style="font-size: 15px;">Kaggle</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/信息隐藏/" style="font-size: 15px;">信息隐藏</a> <a href="/tags/Steganography/" style="font-size: 15px;">Steganography</a> <a href="/tags/语义分割/" style="font-size: 15px;">语义分割</a> <a href="/tags/面经/" style="font-size: 15px;">面经</a> <a href="/tags/Neural-Network/" style="font-size: 15px;">Neural Network</a> <a href="/tags/机器学习基石/" style="font-size: 15px;">机器学习基石</a> <a href="/tags/steganalysis/" style="font-size: 15px;">steganalysis</a> <a href="/tags/Pose-Estimation/" style="font-size: 15px;">Pose Estimation</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/01/My-reading-list2/">My reading list</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/27/小米面经/">小米面经</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/10/关于sematic-segmentation的几篇论文（二）/">关于sematic segmentation的几篇论文（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/论文阅读：RealTime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/">论文阅读：RealTime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/关于semantic-segmentation的几篇论文/">关于semantic segmentation的几篇论文</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/06/于众目睽睽之下隐藏图像：深度隐写术/">于众目睽睽之下隐藏图像：深度隐写术</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/08/深度学习在信息隐藏中的应用（下）/">深度学习在信息隐藏中的应用（下）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/06/深度学习在信息隐藏中的应用（上）/">深度学习在信息隐藏中的应用（上）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/14/使用Tensorflow实现Titanic比赛/">使用Tensorflow实现Titanic比赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/19/Python爬虫小结之Selenium/">Python爬虫小结之Selenium</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://killersdeath.github.io" title="抄作业的小东" target="_blank">抄作业的小东</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Marcovaldo.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'marcovaldo'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2be92f134440f46356c71aa55035a144";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>