<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="日拱一卒，功不唐捐"><title>Python爬虫小结之Selenium | Marcovaldo</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python爬虫小结之Selenium</h1><a id="logo" href="/.">Marcovaldo</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/LeetCode/"><i class="fa fa-list"> LeetCode</i></a><a href="/Booklist/"><i class="fa fa-book"> Booklist</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Python爬虫小结之Selenium</h1><div class="post-meta">Feb 19, 2017<span> | </span><span class="category"><a href="/categories/爬虫/">爬虫</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2017/02/19/Python爬虫小结之Selenium/" href="/2017/02/19/Python爬虫小结之Selenium/#comments" class="ds-thread-count"></a><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#BeautifulSoup和Xpath的比较"><span class="toc-number">1.</span> <span class="toc-text">BeautifulSoup和Xpath的比较</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#如何爬取JSON动态加载的网站"><span class="toc-number">2.</span> <span class="toc-text">如何爬取JSON动态加载的网站</span></a></li></ol></div></div><div class="post-content"><p>上学期和同学一块儿接了个爬虫的活儿，赚了人生第一桶金。本来打算寒假好好整理一下，但是，但是寒假整整玩儿了一个月，说好的总结博客没有写，想学的新东西也没有看，真是不思进取啊。现在提前几天回学校，一来准备一下实验室新开的项目，二来对这学期做一个小的规划吧，顺带整理一下上学期的工作。这篇博客主要总结了我在这个爬虫项目中学习到的一些新知识，在此要感谢我的两位同学<a href="https://www.zhihu.com/people/killers-death/activities" target="_blank" rel="external">killers Death</a>和<a href="https://www.zhihu.com/people/zhong-yao-46/activities" target="_blank" rel="external">yohoho</a>。<br><a id="more"></a><br>这个项目主要是抓取某几个网站（其中包括淘宝）的商品列表和商品详情。我们的整体思路是将抓取到的商品列表和商品详情分别保存在MySQL中，并且在其中加入了类似『断点续传』的功能——即爬虫在断掉后重新抓取时只抓取那些未抓取的商品详情。</p>
<h2 id="BeautifulSoup和Xpath的比较"><a href="#BeautifulSoup和Xpath的比较" class="headerlink" title="BeautifulSoup和Xpath的比较"></a>BeautifulSoup和Xpath的比较</h2><p>解析网页的方法有好几种，我以前只会使用beautifulsoup，写起来既麻烦，速度又慢，这次我们使用了xpath和正则表达式。借助chrome中的开发者工具我们可以迅速拿到页面中任意信息对应的xpath语句，节省了使用beautifulsoup中的find方法时的一次次调试。另外xpath解析网页的速度要比beautifulSoup快十几倍，二者具体的比较见<a href="https://www.zhihu.com/question/26494302/answer/78528053" target="_blank" rel="external">python中的beautifulsoup和xpath有什么异同点？ - 彭泉鑫的回答 - 知乎</a>。</p>
<h2 id="如何爬取JSON动态加载的网站"><a href="#如何爬取JSON动态加载的网站" class="headerlink" title="如何爬取JSON动态加载的网站"></a>如何爬取JSON动态加载的网站</h2><p>我们爬的第一个网站是<a href="http://www.vipmro.com/" target="_blank" rel="external">工品汇</a>，这个网站看起来很规整啊。上来按照常规方法去抓取商品详情，结果什么都没有拿到，这就有点儿懵逼了。查了一下了解到有些网站是通过json动态加载的，然后我们查到了Phantomjs，通过这个工具成功抓到了商品详情。下面介绍一下如何使用这个：</p>
<ul>
<li>安装<a href="http://phantomjs.org/download.html" target="_blank" rel="external">Phantomjs</a></li>
<li>安装<a href="http://www.tornadoweb.org/en/stable/" target="_blank" rel="external">tornado</a></li>
<li>在工作路径下添加文件<a href="https://github.com/2shou/PhantomjsFetcher/blob/master/phantomjs_fetcher.js" target="_blank" rel="external">phantonjs_fetcher.js</a>，然后在控制台用命令”phantomjs phantomjs_fetcher.js [port]”来启动它（这里的port随便填一个即可）</li>
</ul>
<p>做完上面的工作后，我们再用下边的这个函数就可以拿到json动态加载之后的信息了。之后再按照常规的方法就可以拿到整个网站的三级列表，可以正常的抓取商品详情了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getHtmlFromJs</span><span class="params">(url)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    获取js加载数据后的html</div><div class="line">    :param url:请求url</div><div class="line">    :return:</div><div class="line">    '''</div><div class="line">    fetcher=Fetcher(</div><div class="line">          user_agent=<span class="string">'phantomjs'</span>, <span class="comment"># user agent</span></div><div class="line">          phantomjs_proxy=<span class="string">'http://localhost:4444'</span>, <span class="comment"># phantomjs url</span></div><div class="line">          pool_size=<span class="number">10</span>, <span class="comment"># max httpclient num</span></div><div class="line">          <span class="keyword">async</span>=<span class="keyword">False</span></div><div class="line">          )</div><div class="line">    <span class="keyword">return</span> fetcher.phantomjs_fetch(url)</div></pre></td></tr></table></figure>
<p>一般在抓取某一个目录下的所有商品的url列表时，网站会通过接口来返回url列表，我们只需要通过不断改变要请求的接口链接中的参数就可以实现网页的翻页，从而拿到整个分类下的所有商品url。我之前在爬取知乎大V的follower列表时就是这个样子，具体可以阅读我<a href="https://marcovaldong.github.io/2016/08/18/Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E5%B0%8F%E7%BB%93/">前面的那篇博客</a>。但是这个网站明显不是这样的，我们用常规方法只能抓到第一页，拿不到什么接口，也没有什么下一页的链接，这就又懵逼了。另外一个问题是每个三级目录下最多只显示7页x15条/页=105条商品详情（网页只显示有100件相关商品），如果想拿到所有的数据（如135条）的话，我们就需要在爬虫时自动的遍历选择条件（如下图所示），以前的方法里并没有这个功能。</p>
<p><img src="http://7xsbsy.com1.z0.glb.clouddn.com/%E7%88%AC%E8%99%AB%E6%80%BB%E7%BB%93-%E6%9D%A1%E4%BB%B6%E9%80%89%E6%8B%A9.png" alt=""></p>
<p>经过又一番搜索，我们找到了Selenium。Selenium是一个自动化测试工具，支持Chrome，Firefox等主流界面式浏览器，只要在浏览器里边安装一个Selenium的插件，然后就可以实现Web界面的测试。另外Selenium支持多种语言开发，如JAVA，C，Python。这里我们便开始借助Selenium来解决上面遇到的两个问题。首先是完成如下准备工作：</p>
<ul>
<li>安装Selenium</li>
<li>安装Firefox及Selenium插件</li>
<li>安装Selenium库（通过pip命令安装即可）</li>
<li>快速学习Selenium<a href="http://selenium-python.readthedocs.io/" target="_blank" rel="external">官方文档</a></li>
</ul>
<p>在写这篇博客时看到了大神崔庆才的<a href="http://cuiqingcai.com/2599.html" target="_blank" rel="external">博客</a>，这里也贴一下。下面直接给出两个函数，第一个函数解决的是翻页的问题，第二个函数则实现了条件选择，拿到了每一种条件选择对应的url。值得一提的是，代码跑起来时，网页自己进行翻页和条件选择的画面看着很magic啊，哈哈哈。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">goodsUrlList</span><span class="params">(home_url)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    根据三级目录商品首页获取所有详情页url</div><div class="line">    :param home_url: http://www.vipmro.com/search/?&amp;categoryId=501110</div><div class="line">    :return:url列表</div><div class="line">    '''</div><div class="line">    <span class="string">'''</span></div><div class="line">    # 所有条件下的列表</div><div class="line">    all_group_list = parseOptional(home_url)</div><div class="line">    # 保存所有goods的详情页url</div><div class="line">    url_list = []</div><div class="line">    for url in all_group_list:</div><div class="line">        # url = 'http://www.vipmro.com/search/?ram=0.9551325197768372&amp;categoryId=501110&amp;attrValueIds=509805,509801,509806,509807'</div><div class="line">        # 解析html</div><div class="line">        home_page = getHtmlFromJs(url)['content'].encode('utf-8')</div><div class="line">        html = HtmlResponse(url=url,body=str(home_page))</div><div class="line">        urls = html.selector.xpath('/html/body/div[7]/div[1]/ul/li/div[2]/a/@href').extract()</div><div class="line">        if not urls:</div><div class="line">            continue</div><div class="line">        url_list.extend(urls)</div><div class="line">    return url_list</div><div class="line">    '''</div><div class="line">    urls = []  <span class="comment"># 存储种子url</span></div><div class="line">    driver = webdriver.Firefox()</div><div class="line">    driver.get(url)</div><div class="line">    path = <span class="string">'/html/body/div[7]/div[2]/a[@page-id="&#123;0&#125;"]'</span></div><div class="line">    time.sleep(<span class="number">3</span>)</div><div class="line">    page = driver.page_source</div><div class="line">    html = HtmlResponse(url=url, body=str(page))</div><div class="line">    url_tmp = html.selector.xpath(<span class="string">'/html/body/div[7]/div[1]/ul/li/div[2]/a/@href'</span>).extract()</div><div class="line">    urls.extend(url_tmp)</div><div class="line">    <span class="keyword">print</span> len(urls)</div><div class="line">    num = int(re.findall(<span class="string">r'\d+'</span>, html.xpath(<span class="string">'/html/body/div[6]/div/div[4]/span/text()'</span>).extract()[<span class="number">0</span>])[<span class="number">0</span>])</div><div class="line">    <span class="keyword">if</span> num &lt;= <span class="number">15</span>:  <span class="comment"># 只有一页</span></div><div class="line">        <span class="keyword">return</span> urls</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        <span class="keyword">import</span> math</div><div class="line">        page_num = int(math.ceil(num / <span class="number">15.0</span>))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, page_num):</div><div class="line">            <span class="comment"># 模拟翻页动作</span></div><div class="line">            driver.find_element_by_xpath(path.format(<span class="number">1</span> + i)).click()</div><div class="line">            time.sleep(<span class="number">2</span>)</div><div class="line">            <span class="comment"># 提取html语句，解析</span></div><div class="line">            page = driver.page_source</div><div class="line">            html = HtmlResponse(url=url, body=str(page))</div><div class="line">            url_tmp = html.selector.xpath(<span class="string">'/html/body/div[7]/div[1]/ul/li/div[2]/a/@href'</span>).extract()</div><div class="line">            urls.extend(url_tmp)</div><div class="line">    <span class="keyword">print</span> len(urls)</div><div class="line">    driver.quit()</div><div class="line">    <span class="keyword">return</span> urls</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">parseOptional</span><span class="params">(url)</span>:</span></div><div class="line">    <span class="string">'''</span></div><div class="line">    解析url下页面各种选择项组合的url</div><div class="line">    :param url: http://www.vipmro.com/search/?&amp;categoryId=501110</div><div class="line">    :return:['http://www.vipmro.com/search/?categoryId=501110&amp;attrValueIds=509801,512680,509807,509823']</div><div class="line">    '''</div><div class="line">    <span class="comment"># 解析html</span></div><div class="line">    home_page = getHtmlFromJs(url)[<span class="string">'content'</span>].encode(<span class="string">'utf-8'</span>)</div><div class="line">    html = HtmlResponse(url=url,body=str(home_page))</div><div class="line">    <span class="comment"># 系列参数</span></div><div class="line">    xi_lie = html.selector.xpath(<span class="string">'/html/body/div[5]/div[6]/ul/li/a/@href'</span>).re(<span class="string">r'ValueIds=(\d+)'</span>)</div><div class="line">    <span class="comment"># 额定极限分断能力</span></div><div class="line">    fen_duan = html.selector.xpath(<span class="string">'/html/body/div[5]/div[10]/ul/li/a/@href'</span>).re(<span class="string">r'ValueIds=(\d+)'</span>)</div><div class="line">    <span class="comment"># 脱扣器形式</span></div><div class="line">    tuo_kou_qi = html.selector.xpath(<span class="string">'/html/body/div[5]/div[14]/ul/li/a/@href'</span>).re(<span class="string">r'ValueIds=(\d+)'</span>)</div><div class="line">    <span class="comment"># 安装方式</span></div><div class="line">    an_zhuang = html.selector.xpath(<span class="string">'/html/body/div[5]/div[12]/ul/li/a/@href'</span>).re(<span class="string">r'ValueIds=(\d+)'</span>)</div><div class="line">    <span class="comment"># 获取所有参数组合</span></div><div class="line">    all_group = list(itertools.product(xi_lie,fen_duan,tuo_kou_qi,an_zhuang))</div><div class="line">    _url = url + <span class="string">'&amp;attrValueIds='</span></div><div class="line">    url_list = map(<span class="keyword">lambda</span> x:_url+<span class="string">','</span>.join(list(x)),all_group)</div><div class="line"></div><div class="line">    <span class="keyword">return</span> url_list</div></pre></td></tr></table></figure>
<p>由于当时有几个网站要处理，这个网站被放到了最后去爬。后来我们又发现这个网站数据比较少，便放弃了爬这个网站。（这篇博客纯粹是从技术实现的角度来讲的，应该不会对这个网站造成侵权吧）</p>
<p>另外学到的新知识就是如何将数据存储到数据库中，这一方面就不再赘述，等以后学完了MongoDB再一块儿总结吧。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://marcovaldong.github.io/2017/02/19/Python爬虫小结之Selenium/" data-id="cjfguskfv000rcgur3si5xptx" class="article-share-link">分享到</a><div class="tags"><a href="/tags/爬虫/">爬虫</a><a href="/tags/Python/">Python</a></div><div class="post-nav"><a href="/2017/05/14/使用Tensorflow实现Titanic比赛/" class="pre">使用Tensorflow实现Titanic比赛</a><a href="/2016/11/11/My-reading-list/" class="next">My reading list</a></div><div data-thread-key="2017/02/19/Python爬虫小结之Selenium/" data-title="Python爬虫小结之Selenium" data-url="http://marcovaldong.github.io/2017/02/19/Python爬虫小结之Selenium/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  owner: 'marcovaldong',
  repo: 'marcovaldong.github.io',
  oauth: {
    client_id: '3f1a34510c57772de8f8',
    client_secret: '69b8be94d1b53df548e46b9be32356b79e974d3c',
  },
})
gitment.render('container')
</script><div data-thread-key="2017/02/19/Python爬虫小结之Selenium/" data-title="Python爬虫小结之Selenium" data-url="http://marcovaldong.github.io/2017/02/19/Python爬虫小结之Selenium/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://marcovaldong.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/信息隐藏/">信息隐藏</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Neural-Network/">Neural Network</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Deep-Learning/" style="font-size: 15px;">Deep Learning</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Theano/" style="font-size: 15px;">Theano</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Kaggle/" style="font-size: 15px;">Kaggle</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/信息隐藏/" style="font-size: 15px;">信息隐藏</a> <a href="/tags/Steganography/" style="font-size: 15px;">Steganography</a> <a href="/tags/语义分割/" style="font-size: 15px;">语义分割</a> <a href="/tags/面经/" style="font-size: 15px;">面经</a> <a href="/tags/Neural-Network/" style="font-size: 15px;">Neural Network</a> <a href="/tags/机器学习基石/" style="font-size: 15px;">机器学习基石</a> <a href="/tags/steganalysis/" style="font-size: 15px;">steganalysis</a> <a href="/tags/Pose-Estimation/" style="font-size: 15px;">Pose Estimation</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/04/01/My-reading-list2/">My reading list</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/27/小米面经/">小米面经</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/01/10/关于sematic-segmentation的几篇论文（二）/">关于sematic segmentation的几篇论文（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/论文阅读：RealTime-Multi-Person-2D-Pose-Estimation-using-Part-Affinity-Fields/">论文阅读：RealTime Multi-Person 2D Pose Estimation using Part Affinity Fields</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/31/关于semantic-segmentation的几篇论文/">关于semantic segmentation的几篇论文</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/06/于众目睽睽之下隐藏图像：深度隐写术/">于众目睽睽之下隐藏图像：深度隐写术</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/08/深度学习在信息隐藏中的应用（下）/">深度学习在信息隐藏中的应用（下）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/06/深度学习在信息隐藏中的应用（上）/">深度学习在信息隐藏中的应用（上）</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/14/使用Tensorflow实现Titanic比赛/">使用Tensorflow实现Titanic比赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/19/Python爬虫小结之Selenium/">Python爬虫小结之Selenium</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://killersdeath.github.io" title="抄作业的小东" target="_blank">抄作业的小东</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Marcovaldo.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'marcovaldo'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2be92f134440f46356c71aa55035a144";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>