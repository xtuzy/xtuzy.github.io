<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="日拱一卒，功不唐捐"><title>MLDS2017大作业 | Marcovaldo</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/4.2.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.0.0/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MLDS2017大作业</h1><a id="logo" href="/.">Marcovaldo</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MLDS2017大作业</h1><div class="post-meta">Jun 27, 2017<span> | </span><span class="category"><a href="/categories/Machine-Learning/">Machine Learning</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><a data-thread-key="2017/06/27/MLDS2017大作业/" href="/2017/06/27/MLDS2017大作业/#comments" class="ds-thread-count"></a><div class="post-content"><h3 id="第一题"><a href="#第一题" class="headerlink" title="第一题"></a>第一题</h3><h4 id="1"><a href="#1" class="headerlink" title="(1)"></a>(1)</h4><p>网络结构图如下所示，其中$x_i$表示输入数据的第i维，代表输入单元，输入层最后一个神经元表示偏置；$f_i^{(1)}$和$f_i^{(2)}$分别表示第一层和第二层的神经元；输出层中的$\varphi_i$表示激活函数。（没有使用画图软件，直接手画的，不太好看^_..^）<br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLDS_final_mlp.png" alt="图1-1"></p>
<h4 id="2"><a href="#2" class="headerlink" title="(2)"></a>(2)</h4><p>编码形式采用零一编码，即十类数据的label分别记为$(1,0,0,0,0,0,0,0,0,0), (0,1,0,0,0,0,0,0,0,0),..., (0,0,0,0,0,0,0,0,0,1)$。记每组数据的真实label为$y=(y_1,y_2,...,y_C)$，记模型的输出为$\hat{y}=(\hat{y}_1,\hat{y}_2,...,\hat{y}_C)$，模型则将一组训练数据的label标记为输出$\hat{y}$中最大的分量所对应的位数。例如，若一组输入数据的输出为$(0.1, 0.97,0.34,0.21,0.25,0.32,0.19,0.08,0.11,0.15)$，则将该组数据的label标记为2。<br><a id="more"></a><br>代价函数选择平方差误差函数，则代价函数为：<br>$$e = \frac{1}{2n}\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{C}(y_j^i-\hat{y}_j^i)^2\tag{1}$$<br>其中，n表示训练数据的个数，C表示类别数目，题设中将C指定为10。</p>
<h4 id="3"><a href="#3" class="headerlink" title="(3)"></a>(3)</h4><p>根据题设，我们这里将激活函数确定为$\varphi(v)=\frac{1}{1+e^{-v}}$，将第一层和第二层的函数确定为$f(x)=wx$。<br>题设要求计算输出层的误差信号传播到第1层会衰减多少，首先我们确定输出层的误差信号（这里只写了在一个数据上的误差，多个数据的话在公式外层再加一个sigma求和即可）为：<br>$$e = \frac{1}{2}\sum\limits_{j=1}^{C}(y_j-\hat{y}_j)^2 \\ = \frac{1}{2}\sum\limits_{j=1}^{10}(\varphi_j-y_j)^2\tag{2}$$<br>先根据Backpropagation去求偏导：<br>$$\frac{\partial{e}}{\partial{f_k^{(1)}}} = \sum\limits_{i=1}^{50}\frac{\partial{e}}{\partial{f_i^{(2)}}}\frac{\partial{f_i^{(2)}}}{\partial{(f_k^{(1)})}} \\ = \sum\limits_{i=1}^{50}\frac{\partial{e}}{\partial{f_i^{(2)}}}W_{ki}^{(2)} \\ =\sum\limits_{i=1}^{50}\sum\limits_{j=1}^{10}\frac{\partial{e}}{\partial{\varphi_j}}\frac{\partial{\varphi_j}}{\partial{f_i^{(2)}}}W_{ki}^{(2)} \\ = \sum\limits_{i=1}^{50}\sum\limits_{j=1}^{10}\frac{\partial{e}}{\partial{\varphi_j}}f_i^{(2)}(1-f_i^{(2)})W_{ki}^{(2)} \\ = \sum\limits_{i=1}^{50}\sum\limits_{j=1}^{10}\varphi_jf_i^{(2)}(1-f_i^{(2)})W_{ij}^{(3)}W_{ki}^{(2)} \\ = \sum\limits_{i=1}^{50}\sum\limits_{j=1}^{10}\varphi_jf_i^{(2)}(1-f_i^{(2)})W_{ki}^{(2)}W_{ij}^{(3)}\tag{3}$$<br>所以，输出层的误差信号传播到第1层的衰减就应该是(3)式，如果激活函数是ReLu的话，只需将(3)式中的$\frac{\partial{\varphi_j}}{\partial{f_i^{(2)}}}$替换成ReLu的导数，得到下式：
$$\sum\limits_{i=1}^{50}\sum\limits_{j=1}^{10}\varphi_jW_{ki}^{(23)}W_{ij}^{(32)}\tag{4}$$</p>
<h4 id="4"><a href="#4" class="headerlink" title="(4)"></a>(4)</h4><p>将原代价函数记为$e$，新的代价函数记为$e^{'}$，则有：
$$e^{'} = e + \frac{\lambda_1}{2}\left\|W^{(1)}\right\|_F^2 + \frac{\lambda_2}{2}\left\|W^{(2)}\right\|_F^2$$
对于参数$W_{ij}^{(1)}$来说，原来的权值更新公式为：
$$W_{ij}^{(1)new} = W_{ij}^{(1)old} - \alpha\frac{\partial{e}}{\partial{W_{ij}^{(1)}}} \\ = W_{ij}^{(1)old} - \alpha\frac{\partial{e}}{\partial{f_j^{(1)}}}\frac{\partial{f_j^{(1)}}}{\partial{W_{ij}^{(1)}}} \\ = W_{ij}^{(1)old} - \alpha\frac{\partial{e}}{\partial{f_j^{(1)}}}x_i\tag{5}$$
其中$\alpha$为学习率，$\frac{\partial{e}}{\partial{f_j^{(1)}}}$见第(3)问，则新的权值更新公式为：
$$W_{ij}^{(1)new} = W_{ij}^{(1)old} - \alpha\frac{\partial{e^{'}}}{\partial{W_{ij}^{(1)}}} \\ = W_{ij}^{(1)old} - \alpha\frac{\partial{e}}{\partial{W_{ij}^{(1)}}} - \lambda_1W_{ij}^{(1)old} \\ = W_{ij}^{(1)old} - \alpha\frac{\partial{e}}{\partial{f_j^{(1)}}}x_i - \lambda_1W_{ij}^{(1)old}\tag{6}$$
同理，$W_{ij}^{(2)}$的权值更新公式由
$$W_{ij}^{(2)new} = W_{ij}^{(2)old} - \alpha\frac{\partial{e}}{\partial{f_j^{(2)}}}f_i^{(1)}\tag{7}$$
变为
$$W_{ij}^{(2)new} = W_{ij}^{(2)old} - \alpha\frac{\partial{e}}{\partial{f_j^{(2)}}}f_i^{(1)} - \lambda_2W_{ij}^{(2)old}\tag{8}$$
其中，$\frac{\partial{e}}{\partial{f_j^{(2)}}}$的推导类似于第(3)问。</p>
<h3 id="第二题"><a href="#第二题" class="headerlink" title="第二题"></a>第二题</h3><h4 id="1-1"><a href="#1-1" class="headerlink" title="(1)"></a>(1)</h4>阅读题目，我认为题设的意思是在$x_j$所在的$R^m$空间内寻找一组规范正交基，基的个数为$r < m$。用这组基去近似的线性表示每个数据$x_j$，得到一个系数向量$(x_j^Tp_1, x_j^Tp_2,...,x_j^Tp_r)^T$，用这个长度为r的系数向量来表示原来长度为m的数据$x_j$，从而达到了降维的目的。随后我们就可以用降维后的数据去做分类等任务。<br><br>题目中的原始优化问题如下：<br>$$\min_{p_i,i=1,...,r}\sum\limits_{j=1}^{n}\left\|x_j - \sum\limits_{i=1}^{r}p_ix_j^Tp_i\right\|_2^2\tag{1}$$
<p>首先，我们来计算$\left\|x_j - \sum\limits_{i=1}^{r}p_ix_j^Tp_i\right\|_2^2$，将其展开有：
$$\left\|x_j - \sum\limits_{i=1}^{r}p_ix_j^Tp_i\right\|_2^2 = x_j^Tx_j - 2\sum\limits_{i=1}^{r}x_j^Tp_ix_j^Tp_i + (\sum\limits_{i=1}^{r}p_ix_j^Tp_i)^2\tag{2}$$<br>其中，$x_j^Tp_i$为一个标量，即(2)式的最后一项是$p_i$的线性组合后再平方；又因为{$p_i, i=1, ..., r$}是一组规范正交基，因此交叉项为零，即
$$(\sum\limits_{i=1}^{r}p_ix_j^Tp_i)^2 = \sum\limits_{i=1}^{r}(p_ix_j^Tp_i)^2\\ = \sum\limits_{i=1}^{r}(p_ix_j^Tp_i)^T(p_ix_j^Tp_i) \\ = \sum\limits_{i=1}^{r}(p_i^Tx_jp_i^Tp_ix_j^Tp_i) \\ = \sum\limits_{i=1}^{r}(p_i^Tx_jx_j^Tp_i)\tag{3}$$
又因为$x_j^Tp_i=p_i^Tx_j$为标量，所以(2)式第二项中的$x_j^Tp_ix_j^Tp_i$可以写成$p_i^Tx_jx_j^Tp_i$，因此(2)式可以写成如下形式：
$$\left\|x_j - \sum\limits_{i=1}^{r}p_ix_j^Tp_i\right\|_2^2 = x_j^Tx_j - 2\sum\limits_{i=1}^{r}p_i^Tx_jx_j^Tp_i + \sum\limits_{i=1}^{r}p_i^Tx_jx_j^Tp_i\\ = x_j^Tx_j - \sum\limits_{i=1}^{r}p_i^Tx_jx_j^Tp_i\tag{4}$$<br>将(4)式带入(1)式中即有：<br>$$\min_{p_i,i=1,...,r}\sum\limits_{j=1}^{n}(x_j^Tx_j - \sum\limits_{i=1}^{r}p_i^Tx_jx_j^Tp_i) \\ = \min_{p_i,i=1,...,r}(\sum\limits_{j=1}^{n}x_j^Tx_j - \sum\limits_{j=1}^{n}\sum\limits_{i=1}^{r}p_i^Tx_jx_j^Tp_i)\tag{5}$$<br>此时，我们就可以将优化问题转换成矩阵形式，得到：<br>$$\min_{P} tr(X^TX - P^TXX^TP)\tag{6}$$<br>其实上式中的$tr(X^TX - P^TXX^TP)$写成$tr(X^TX) - tr(P^TXX^TP)$更合理，因为$X^TX$是一个mxm的矩阵，$P^TXX^TP$是一个rxr的矩阵，不过推导可知$tr(P^TXX^TP)$正好就是(5)式中的$\sum\limits_{j=1}^{n}\sum\limits_{i=1}^{r}p_i^Tx_jx_j^Tp_i$。</p>
<p>运用Lagrange乘子法构造辅助函数，即下面的(7)式：<br>$$L = X^TX - P^TXX^TP + \lambda(P^TP - I)\tag{7}$$<br>其中$I$为单位矩阵。令偏导$\frac{\partial{L}}{\partial{P}}=0$则得到了求解特征值与特征向量问题：<br>$$XX^TP = \lambda{P}\tag{8}$$<br>综上所述，由矩阵$XX^T$的部分特征向量组成的一组规范正交基即是该问题的最优解。</p>
<h4 id="2-1"><a href="#2-1" class="headerlink" title="(2)"></a>(2)</h4><p>我的思路是这样的，根据第一问中的结果先计算出$XX^T$，对其进行特征分解，得到m个单位向量组成的规范正交基，我们要求的P即是它的子集。</p>
<p>根据(2)式和(6)式，在计算误差时我们只需计算$X^TX$和$P^TXX^TP$两个矩阵的trace即可。另外由于正交性及题设，我们只需要一个个的去选择$p_i$即可。因此，我们将前面得到的m个特征向量分别代入(6)式中（此时矩阵$P$的尺寸就是mx1），分别求得误差，选择误差最小的前r个。通过计算我们发现，由大的特征值对应的特征向量求得的误差小，由小的特征值对应的特征向量求得的误差大，因此我们可以选择前ｒ大的特征值对应的ｒ个特征向量来做待求的那组规范正交基。</p>
<p>至于ｒ的选择，我觉得要根据经验找到一个误差阈值。随着ｒ由１开始增大，误差不断减小，当误差刚好在误差阈值以下时，ｒ不再增大，我们选择此时的ｒ值来做我们整个问题的ｒ值。具体的代码和求解情况我都放在了第(3)问。</p>
<h4 id="3-1"><a href="#3-1" class="headerlink" title="(3)"></a>(3)</h4><p>借助Python实现了本题中的求解。首先对矩阵$XX^T$进行特征分解，得到一组规范正交基。然后分别将单个特征向量代入(1)式或(6)式中去计算误差，得出大的特征值对应的特征向量要优于小的特征值对应的特征向量。需要注意的是，矩阵计算要比标量计算快很多，我分别试了两种方式，用标量方式去计算大概需要40min，而使用矩阵方式去计算大概只需要32s。代码见附录。（可能是我前者的代码写的不好导致相差太大，但矩阵绝对比标量快）</p>
<p>下面第一张图显示了单个特征向量求得的误差的变化情况，横坐标上从左到右256个点表示的是从大到小的特征值，纵坐标表示(1)式的误差值。可以看到大的特征值对应的特征向量求得的误差值小，小的特征值对应的特征向量求得的误差值大，误差值从800000左右增大到1600000，增大了一倍。<br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLDS_final_2_1.png" alt="图2-1"><br>第二张图是题设中要求的图，即不同的r值对应的误差值的变化情况，横坐标表示r值，纵坐标表示误差值。可以看到随着特征向量数量的增多，误差值越来越小，由1个向量时的800000降到60个特征向量时的77578，再到160个特征向量时的10692，到最后256个特征向量时的0。这是一个很自然的事情，特征向量越多越能还原数据本来的样子。所以r的选择需要我们根据经验去得到一个经验误差阈值，一旦误差小于这个阈值，r就不再增大，我们就选择当前的r值作为我们最后的r值，用$XX^T$的前r大特征值对应的特征向量去对原数据进行线性近似得到降维后的数据。<br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLDS_final_2_2.png" alt="图2-2"><br>最后题设要求画出前20个最优解所对应的图像，我的理解是利用降维后得到的新的特征向量和正交基$P$去重构出来原始数据，通过可视化比较降维前后信息的丢失程度。USPS是一个手写识别的数据集，这里我在每一类中分别选取了一个样本来进行降维，然后用降维后的数据及正交基P对数据进行还原，比较前后的差别。下图中的样本类别分别是[6, 5, 4, 7, 3, 1, 0, 8, 2, 9]。具体的，由于每个原始数据都是一个256维的向量，把它转换成一个16*16的矩阵；又因为原始数据中都是小数，这里对每个小数都乘上100，表示每个点对应的像素值。对于重构出来的256维向量同样乘上100，表示还原图像中每个点的像素值。可以看到，使用规范正交基重构出来的图像相较于原始图像，丢失的信息还不算多，基本能还原原始图像的信息。另外，我还加入了前10个最优解和前100个最优解所对应的图像，见最后两张图。通过比较前后三张图，我们可以清晰的看到，r越大，规范正交基的重构能力越强，越能真实的近似原始信息。<br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLDS_final_2_3.png" alt="图2-3"><br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLDS_final_2_4.png" alt="图2-4"><br><img src="http://7xsbsy.com1.z0.glb.clouddn.com/MLDS_final_2_5.png" alt="图2-5"></p>
<h3 id="第三题"><a href="#第三题" class="headerlink" title="第三题"></a>第三题</h3><p>其实我去年休学在家的时候在Cousera上自学了Andrew Ng的Machine Learning、台大林轩田老师的机器学习基石和hinton教授的Neural Networks for Machine Learning（后两个课都没看完）以及李航博士的《统计学习方法》，所以MLDS2017里边的很多内容我以前就知道。这学期不仅复习了以前的知识，更重要的是学了很多新东西，主要有以下几方面：</p>
<ul>
<li>关于正则化的理论推导，不过不是很明白，也不会用。以前只知道正则化是在损失函数后边加上个W的L2范数；</li>
<li>各种降维方法，之前只知道PCA，现在了解了各种降维方法，如果我的第二题正确的话，那我也就算掌握了如何去对原始数据做降维了；</li>
<li>关于压缩感知的方法，不过也不是很明白，还不会用；</li>
<li>最后一点，也是最重要的一点，就是领略了李老师的治学态度，另学生钦佩，也令学生感到汗颜。很遗憾没有及时完成每次的作业，争取这个夏天能在课余时间复习MLDS的课件，继续学习新的理论知识和实践工具。</li>
</ul>
<p>我最感兴趣的部分是深度学习，因为感觉神经网络现在好像几乎可以去解决机器学习领域中的任何问题，如计算机视觉、NLP等，不过这方面现在我只能写个小小的demo，解决手写识别这样的问题，所以还有太多的东西需要学习。另外感兴趣的是降维和压缩感知，感觉这两点都可以用在机器视觉上，而我对机器视觉比较感兴趣。</p>
<h3 id="第四题"><a href="#第四题" class="headerlink" title="第四题"></a>第四题</h3><p>总体感觉，MLDS2017的课程安排很充实，涉及到了机器学习的方方面面，很受益。一个小小的建议是能不能稍微减少一些数学推导，多一些其他的内容。我不了解其他同学的情况，我本科是信息与计算科学专业（数学类）的，这门课中的大量数学推导对我来说很吃力，例如关于VC维的推导我完全没有听懂；。后面关于降维的那些推导我基本都能听懂，课下大概也能自己推一下。虽然机器学习本身就包含了大量的数学，但是有些问题能不能换一个角度来解释，例如林轩田的《机器学习基石》中也有关于VC维的解释，里边是借助了一个抓玻璃球的例子来引出的，大概能听明白。当然我举的这个例子也可能是不恰当的，这门课本来就是机器学习的进阶课程，纯数学的推导才能从本质上解释问题。另外很遗憾的是没能听到第十讲的内容，如果李老师之前已经做好课件的话能不能上传一下。</p>
<p>最后强烈建议李老师下次开课时能录视频，并上传到Cousera等MOOC平台上，让更多的人学习，我们也可以再去学习（小私心^_^）。</p>
<p>最后的最后，感谢李老师一学期来的悉心教授，学生受益匪浅。</p>
<h3 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h3><p>本部分为第二题的Python实现。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> scipy</div><div class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</div><div class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> linalg <span class="keyword">as</span> LA</div><div class="line"><span class="keyword">import</span> random</div><div class="line"><span class="keyword">import</span> time</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">ReadData</span><span class="params">(filepath)</span>:</span></div><div class="line">    <span class="comment"># matfilepath = '/home/marcovaldo/MLDS/homework/toydata.mat'</span></div><div class="line">    matfilepath = filepath</div><div class="line">    dataset = sio.loadmat(matfilepath)</div><div class="line">    <span class="comment"># print dataset</span></div><div class="line">    X = dataset[<span class="string">'X'</span>]</div><div class="line">    label = dataset[<span class="string">'index'</span>]</div><div class="line">    <span class="comment"># print np.shape(X)</span></div><div class="line">    <span class="comment"># label = np.array(label, dtype=float)</span></div><div class="line">    <span class="comment"># print np.shape(label)</span></div><div class="line">    <span class="keyword">return</span> (X, label)</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">problem1</span><span class="params">()</span>:</span></div><div class="line">    start = time.time()</div><div class="line">    filepath = <span class="string">'USPS_256x7291.mat'</span></div><div class="line">    X, label = ReadData(filepath)</div><div class="line">    XXT = X.dot(X.transpose())</div><div class="line">    <span class="comment"># vecs中存储的即是256个特征向量，从左到右对应的特征值从大到小</span></div><div class="line">    vecs = scipy.linalg.orth(XXT)</div><div class="line">    <span class="comment"># 矩阵化</span></div><div class="line">    XTX = X.transpose().dot(X)</div><div class="line">    <span class="comment"># print np.shape(XTX)</span></div><div class="line">    XTXTrace = XTX.trace()</div><div class="line">    diffs = []</div><div class="line">    <span class="comment"># 求解每个向量对应的误差值</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">256</span>):</div><div class="line">        tmp = vecs[:,i].transpose().dot(X).dot(X.transpose()).dot(vecs[:,i])</div><div class="line">        diff = XTXTrace - tmp</div><div class="line">        <span class="keyword">print</span> i, diff</div><div class="line">        diffs.append(diff)</div><div class="line">    <span class="comment"># 可视化</span></div><div class="line">    x = range(<span class="number">1</span>, <span class="number">257</span>)</div><div class="line">    plt.xlabel(<span class="string">"Eigenvectors represented by numbers"</span>)</div><div class="line">    plt.ylabel(<span class="string">'Error'</span>)</div><div class="line">    plt.plot(x, diffs, c=<span class="string">'r'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">problem2</span><span class="params">()</span>:</span></div><div class="line">    start = time.time()</div><div class="line">    filepath = <span class="string">'USPS_256x7291.mat'</span></div><div class="line">    X, label = ReadData(filepath)</div><div class="line">    XXT = X.dot(X.transpose())</div><div class="line">    <span class="comment"># vecs中存储的即是256个特征向量，从左到右对应的特征值从大到小</span></div><div class="line">    vecs = scipy.linalg.orth(XXT)</div><div class="line">    <span class="comment"># 矩阵化</span></div><div class="line">    XTX = X.transpose().dot(X)</div><div class="line">    <span class="comment"># print np.shape(XTX)</span></div><div class="line">    XTXTrace = XTX.trace()</div><div class="line">    diffs = []</div><div class="line">    <span class="comment"># 求解前r个特征向量对应的误差值，r从1到256</span></div><div class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">257</span>):</div><div class="line">        tmp = vecs[:,<span class="number">0</span>:r].transpose().dot(X).dot(X.transpose()).dot(vecs[:,<span class="number">0</span>:r])</div><div class="line">        <span class="keyword">if</span> r == <span class="number">1</span>:</div><div class="line">            diff = XTXTrace - tmp</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            diff = XTXTrace - tmp.trace()</div><div class="line">        <span class="keyword">print</span> r, diff</div><div class="line">        diffs.append(diff)</div><div class="line">    diffs[<span class="number">0</span>] = diffs[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>]   <span class="comment"># r等于1时输出的是[[ 811120.41431324]]，所以处理一下</span></div><div class="line"></div><div class="line">    <span class="comment"># 可视化</span></div><div class="line">    x = range(<span class="number">1</span>, <span class="number">257</span>)</div><div class="line">    plt.title(<span class="string">"Error vs. r"</span>)</div><div class="line">    plt.xlabel(<span class="string">"Eigenvectors represented by numbers"</span>)</div><div class="line">    plt.ylabel(<span class="string">'Error'</span>)</div><div class="line">    plt.plot(x, diffs, c=<span class="string">'r'</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">problem3</span><span class="params">()</span>:</span></div><div class="line">    start = time.time()</div><div class="line">    filepath = <span class="string">'USPS_256x7291.mat'</span></div><div class="line">    X, label = ReadData(filepath)</div><div class="line">    XXT = X.dot(X.transpose())</div><div class="line">    <span class="comment"># vecs中存储的即是256个特征向量，从左到右对应的特征值从大到小</span></div><div class="line">    vecs = scipy.linalg.orth(XXT)</div><div class="line">    P = vecs[:, <span class="number">0</span>:<span class="number">10</span>]  <span class="comment"># 前20个特征向量</span></div><div class="line">    <span class="keyword">print</span> np.shape(P)</div><div class="line">    flags = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">7</span>, <span class="number">8</span>, <span class="number">17</span>, <span class="number">41</span>, <span class="number">64</span>]</div><div class="line">    classes = []</div><div class="line">    samples = np.zeros((<span class="number">256</span>, <span class="number">10</span>)) <span class="comment"># 10个样本</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10</span>):</div><div class="line">        samples[:, i] = X[:, flags[i]]</div><div class="line">        classes.append(label[<span class="number">0</span>][flags[i]])</div><div class="line">    <span class="keyword">print</span> classes</div><div class="line">    fix = P.dot(samples.transpose().dot(P).transpose())</div><div class="line">    <span class="keyword">print</span> np.shape(fix)</div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zhuanhuan</span><span class="params">(alist)</span>:</span></div><div class="line">        result = np.zeros((<span class="number">16</span>, <span class="number">16</span>))</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>):</div><div class="line">            result[i] = alist[i * <span class="number">16</span>:(i + <span class="number">1</span>) * <span class="number">16</span>] * <span class="number">100</span></div><div class="line">        <span class="keyword">return</span> result</div><div class="line">    fig = plt.figure()</div><div class="line">    num = <span class="number">0</span></div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</div><div class="line">        num += <span class="number">1</span></div><div class="line">        ax = fig.add_subplot(<span class="number">5</span>, <span class="number">4</span>, num)</div><div class="line">        ax.imshow(zhuanhuan(samples[:, i]), cmap=<span class="string">"gray"</span>)</div><div class="line">        <span class="comment"># ax.set_title(str(classes[i]))</span></div><div class="line">        num += <span class="number">1</span></div><div class="line">        ax = fig.add_subplot(<span class="number">5</span>, <span class="number">4</span>, num)</div><div class="line">        ax.imshow(zhuanhuan(fix[:, i]), cmap=<span class="string">"gray"</span>)</div><div class="line">        <span class="comment"># ax.set_title('fixed' + str(classes[i]))</span></div><div class="line">    plt.show()</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    start = time.time()</div><div class="line">    problem1()</div><div class="line">    problem2()</div><div class="line">    problem3()</div><div class="line">    end = time.time()</div><div class="line">    print(<span class="string">"Time consumption is %.2f sec"</span> % (end - start))</div></pre></td></tr></table></figure></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://marcovaldong.github.io/2017/06/27/MLDS2017大作业/" data-id="cj4fiufc600001kurzoao4yq9" class="article-share-link">分享到</a><div class="tags"><a href="/tags/Machine-Learning/">Machine Learning</a></div><div class="post-nav"><a href="/2017/05/14/使用Tensorflow实现Titanic比赛/" class="next">使用Tensorflow实现Titanic比赛</a></div><div data-thread-key="2017/06/27/MLDS2017大作业/" data-title="MLDS2017大作业" data-url="http://marcovaldong.github.io/2017/06/27/MLDS2017大作业/" class="ds-share flat"><div class="ds-share-inline"><ul class="ds-share-icons-16"><li data-toggle="ds-share-icons-more"><a href="javascript:void(0);" class="ds-more">分享到：</a></li><li><a href="javascript:void(0);" data-service="weibo" class="ds-weibo">微博</a></li><li><a href="javascript:void(0);" data-service="qzone" class="ds-qzone">QQ空间</a></li><li><a href="javascript:void(0);" data-service="qqt" class="ds-qqt">腾讯微博</a></li><li><a href="javascript:void(0);" data-service="wechat" class="ds-wechat">微信</a></li></ul><div class="ds-share-icons-more"></div></div></div><div data-thread-key="2017/06/27/MLDS2017大作业/" data-title="MLDS2017大作业" data-url="http://marcovaldong.github.io/2017/06/27/MLDS2017大作业/" data-author-key="1" class="ds-thread"></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://marcovaldong.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/">Machine Learning</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Machine-Learning/Neural-Network/">Neural Network</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/读书/">读书</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/机器学习/" style="font-size: 15px;">机器学习</a> <a href="/tags/读书/" style="font-size: 15px;">读书</a> <a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Theano/" style="font-size: 15px;">Theano</a> <a href="/tags/Tensorflow/" style="font-size: 15px;">Tensorflow</a> <a href="/tags/Kaggle/" style="font-size: 15px;">Kaggle</a> <a href="/tags/Neural-Network/" style="font-size: 15px;">Neural Network</a> <a href="/tags/机器学习基石/" style="font-size: 15px;">机器学习基石</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/06/27/MLDS2017大作业/">MLDS2017大作业</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/14/使用Tensorflow实现Titanic比赛/">使用Tensorflow实现Titanic比赛</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/02/19/Python爬虫小结之Selenium/">Python爬虫小结之Selenium</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/11/11/My-reading-list/">My reading list</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/18/Python爬虫爬取知乎小结/">Python爬虫爬取知乎小结</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/20/Theano实现kaggle手写识别/">Theano实现kaggle手写识别</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/07/08/Ubuntu14-04-Theano-OpenCL-libgpuarray实现GPU运算/">Ubuntu14.04+Theano+OpenCL+libgpuarray实现GPU运算</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/12/使用Theano实现kaggle手写识别/">使用Theano实现kaggle手写识别</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/30/机器学习中使用的神经网络第十讲/">机器学习中使用的神经网络第十讲</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/21/机器学习中使用的神经网络第九讲/">机器学习中使用的神经网络第九讲</a></li></ul></div><div class="widget"><div class="comments-title"><i class="fa fa-comment-o"> 最近评论</i></div><div data-num-items="5" data-show-avatars="0" data-show-time="1" data-show-admin="0" data-excerpt-length="32" data-show-title="1" class="ds-recent-comments"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">Marcovaldo.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script>var duoshuoQuery = {short_name:'marcovaldo'};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
        || document.getElementsByTagName('body')[0]).appendChild(ds);
})();
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?2be92f134440f46356c71aa55035a144";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>